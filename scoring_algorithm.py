# -*- coding: utf-8 -*-
"""
è¯„åˆ†ç®—æ³•æ¨¡å—
åŸºäºéŸ³é«˜æ¯”è¾ƒæŒ‡æ ‡è®¡ç®—å‘éŸ³è¯„åˆ†
"""
import numpy as np
from config import Config

class ScoringSystem:
    """å‘éŸ³è¯„åˆ†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.weights = Config.SCORE_WEIGHTS
        
        # è¯„åˆ†é˜ˆå€¼é…ç½®
        self.thresholds = {
            'correlation': {
                'excellent': 0.85,  # ä¼˜ç§€
                'good': 0.70,       # è‰¯å¥½
                'fair': 0.50,       # ä¸€èˆ¬
                'poor': 0.30        # è¾ƒå·®
            },
            'rmse': {
                'excellent': 20,    # Hz
                'good': 40,
                'fair': 60,
                'poor': 100
            },
            'trend': {
                'excellent': 0.80,
                'good': 0.65,
                'fair': 0.50,
                'poor': 0.35
            },
            'range': {
                'excellent': 0.85,
                'good': 0.70,
                'fair': 0.50,
                'poor': 0.30
            }
        }
    
    def calculate_score(self, comparison_metrics: dict) -> dict:
        """
        æ ¹æ®æ¯”è¾ƒæŒ‡æ ‡è®¡ç®—ç»¼åˆè¯„åˆ†
        :param comparison_metrics: éŸ³é«˜æ¯”è¾ƒæŒ‡æ ‡
        :return: è¯„åˆ†ç»“æœ
        """
        
        if 'error' in comparison_metrics:
            return {
                'total_score': 0.0,
                'component_scores': {},
                'level': 'é”™è¯¯',
                'feedback': comparison_metrics['error']
            }
        
        metrics = comparison_metrics.get('metrics', {})
        
        # è®¡ç®—å„é¡¹å­åˆ†æ•°
        correlation_score = self._calculate_correlation_score(
            metrics.get('correlation', 0)
        )
        
        rmse_score = self._calculate_rmse_score(
            metrics.get('rmse', float('inf'))
        )
        
        trend_score = self._calculate_trend_score(
            metrics.get('trend_consistency', 0)
        )
        
        range_score = self._calculate_range_score(
            metrics.get('pitch_range_ratio', 0)
        )
        
        # è®¡ç®—åŠ æƒæ€»åˆ†
        total_score = (
            correlation_score * self.weights['correlation'] +
            trend_score * self.weights['trend'] +
            rmse_score * self.weights['stability'] +
            range_score * self.weights['range']
        )
        
        # é™åˆ¶åœ¨0-100åˆ†èŒƒå›´å†…
        total_score = max(0, min(100, total_score))
        
        # ç¡®å®šè¯„çº§
        level = self._get_score_level(total_score)
        
        # ç”Ÿæˆåé¦ˆå»ºè®®
        feedback = self._generate_feedback(metrics, {
            'correlation': correlation_score,
            'rmse': rmse_score,
            'trend': trend_score,
            'range': range_score
        })
        
        return {
            'total_score': round(total_score, 1),
            'component_scores': {
                'accuracy': round(correlation_score, 1),
                'trend': round(trend_score, 1),
                'stability': round(rmse_score, 1),
                'range': round(range_score, 1)
            },
            'level': level,
            'feedback': feedback,
            'metrics': metrics
        }
    
    def _calculate_correlation_score(self, correlation: float) -> float:
        """è®¡ç®—ç›¸å…³æ€§å¾—åˆ†"""
        if correlation >= self.thresholds['correlation']['excellent']:
            return 95 + 5 * (correlation - self.thresholds['correlation']['excellent']) / (1 - self.thresholds['correlation']['excellent'])
        elif correlation >= self.thresholds['correlation']['good']:
            return 80 + 15 * (correlation - self.thresholds['correlation']['good']) / (self.thresholds['correlation']['excellent'] - self.thresholds['correlation']['good'])
        elif correlation >= self.thresholds['correlation']['fair']:
            return 60 + 20 * (correlation - self.thresholds['correlation']['fair']) / (self.thresholds['correlation']['good'] - self.thresholds['correlation']['fair'])
        elif correlation >= self.thresholds['correlation']['poor']:
            return 30 + 30 * (correlation - self.thresholds['correlation']['poor']) / (self.thresholds['correlation']['fair'] - self.thresholds['correlation']['poor'])
        else:
            return max(0, 30 * correlation / self.thresholds['correlation']['poor'])
    
    def _calculate_rmse_score(self, rmse: float) -> float:
        """è®¡ç®—RMSEå¾—åˆ†ï¼ˆå€¼è¶Šå°è¶Šå¥½ï¼‰"""
        if rmse <= self.thresholds['rmse']['excellent']:
            return 100
        elif rmse <= self.thresholds['rmse']['good']:
            return 85 + 15 * (self.thresholds['rmse']['good'] - rmse) / (self.thresholds['rmse']['good'] - self.thresholds['rmse']['excellent'])
        elif rmse <= self.thresholds['rmse']['fair']:
            return 65 + 20 * (self.thresholds['rmse']['fair'] - rmse) / (self.thresholds['rmse']['fair'] - self.thresholds['rmse']['good'])
        elif rmse <= self.thresholds['rmse']['poor']:
            return 35 + 30 * (self.thresholds['rmse']['poor'] - rmse) / (self.thresholds['rmse']['poor'] - self.thresholds['rmse']['fair'])
        else:
            return max(0, 35 * self.thresholds['rmse']['poor'] / rmse)
    
    def _calculate_trend_score(self, trend_consistency: float) -> float:
        """è®¡ç®—è¶‹åŠ¿ä¸€è‡´æ€§å¾—åˆ†"""
        if trend_consistency >= self.thresholds['trend']['excellent']:
            return 95 + 5 * (trend_consistency - self.thresholds['trend']['excellent']) / (1 - self.thresholds['trend']['excellent'])
        elif trend_consistency >= self.thresholds['trend']['good']:
            return 80 + 15 * (trend_consistency - self.thresholds['trend']['good']) / (self.thresholds['trend']['excellent'] - self.thresholds['trend']['good'])
        elif trend_consistency >= self.thresholds['trend']['fair']:
            return 60 + 20 * (trend_consistency - self.thresholds['trend']['fair']) / (self.thresholds['trend']['good'] - self.thresholds['trend']['fair'])
        elif trend_consistency >= self.thresholds['trend']['poor']:
            return 30 + 30 * (trend_consistency - self.thresholds['trend']['poor']) / (self.thresholds['trend']['fair'] - self.thresholds['trend']['poor'])
        else:
            return max(0, 30 * trend_consistency / self.thresholds['trend']['poor'])
    
    def _calculate_range_score(self, range_ratio: float) -> float:
        """è®¡ç®—éŸ³åŸŸé€‚é…å¾—åˆ†"""
        if range_ratio >= self.thresholds['range']['excellent']:
            return 95 + 5 * (range_ratio - self.thresholds['range']['excellent']) / (1 - self.thresholds['range']['excellent'])
        elif range_ratio >= self.thresholds['range']['good']:
            return 80 + 15 * (range_ratio - self.thresholds['range']['good']) / (self.thresholds['range']['excellent'] - self.thresholds['range']['good'])
        elif range_ratio >= self.thresholds['range']['fair']:
            return 60 + 20 * (range_ratio - self.thresholds['range']['fair']) / (self.thresholds['range']['good'] - self.thresholds['range']['fair'])
        elif range_ratio >= self.thresholds['range']['poor']:
            return 30 + 30 * (range_ratio - self.thresholds['range']['poor']) / (self.thresholds['range']['fair'] - self.thresholds['range']['poor'])
        else:
            return max(0, 30 * range_ratio / self.thresholds['range']['poor'])
    
    def _get_score_level(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°ç¡®å®šè¯„çº§"""
        if score >= 90:
            return "ä¼˜ç§€"
        elif score >= 80:
            return "è‰¯å¥½"
        elif score >= 70:
            return "ä¸­ç­‰"
        elif score >= 60:
            return "åŠæ ¼"
        else:
            return "éœ€è¦æ”¹è¿›"
    
    def _generate_feedback(self, metrics: dict, component_scores: dict) -> str:
        """ç”Ÿæˆä¸ªæ€§åŒ–åé¦ˆå»ºè®®"""
        feedback_parts = []
        
        # æ€»ä½“è¯„ä»·
        correlation = metrics.get('correlation', 0)
        if correlation >= 0.8:
            feedback_parts.append("ğŸ‰ æ‚¨çš„å‘éŸ³æ•´ä½“éŸ³è°ƒæŠŠæ¡å¾ˆå¥½ï¼")
        elif correlation >= 0.6:
            feedback_parts.append("ğŸ‘ æ‚¨çš„å‘éŸ³åŸºæœ¬å‡†ç¡®ï¼Œè¿˜æœ‰æå‡ç©ºé—´ã€‚")
        else:
            feedback_parts.append("ğŸ’ª å»ºè®®å¤šç»ƒä¹ ï¼Œæ³¨æ„éŸ³è°ƒçš„èµ·ä¼å˜åŒ–ã€‚")
        
        # å…·ä½“å»ºè®®
        suggestions = []
        
        # éŸ³é«˜å‡†ç¡®æ€§å»ºè®®
        if component_scores['correlation'] < 70:
            suggestions.append("ğŸµ éŸ³é«˜å‡†ç¡®æ€§éœ€è¦æ”¹è¿›ï¼Œå»ºè®®è·Ÿç€æ ‡å‡†å‘éŸ³å¤šç»ƒä¹ éŸ³è°ƒ")
        
        # è¶‹åŠ¿ä¸€è‡´æ€§å»ºè®®
        if component_scores['trend'] < 70:
            suggestions.append("ğŸ“ˆ æ³¨æ„éŸ³è°ƒå˜åŒ–çš„æ–¹å‘ï¼Œç»ƒä¹ å£°è°ƒçš„ä¸Šå‡å’Œä¸‹é™")
        
        # ç¨³å®šæ€§å»ºè®®
        if component_scores['rmse'] < 70:
            suggestions.append("ğŸ¯ å‘éŸ³ç¨³å®šæ€§éœ€è¦åŠ å¼ºï¼Œé¿å…éŸ³è°ƒè¿‡åº¦æ³¢åŠ¨")
        
        # éŸ³åŸŸå»ºè®®
        if component_scores['range'] < 70:
            std_mean = metrics.get('std_mean', 0)
            user_mean = metrics.get('user_mean', 0)
            if user_mean > std_mean * 1.2:
                suggestions.append("ğŸ”½ æ‚¨çš„éŸ³è°ƒåé«˜ï¼Œå¯ä»¥è¯•ç€é™ä½ä¸€äº›")
            elif user_mean < std_mean * 0.8:
                suggestions.append("ğŸ”¼ æ‚¨çš„éŸ³è°ƒåä½ï¼Œå¯ä»¥è¯•ç€æé«˜ä¸€äº›")
            else:
                suggestions.append("ğŸ¼ æ³¨æ„éŸ³è°ƒå˜åŒ–çš„å¹…åº¦ï¼Œåº”è¯¥ä¸æ ‡å‡†å‘éŸ³ä¿æŒä¸€è‡´")
        
        if suggestions:
            feedback_parts.append("\næ”¹è¿›å»ºè®®ï¼š")
            feedback_parts.extend(suggestions)
        else:
            feedback_parts.append("\nç»§ç»­ä¿æŒï¼Œæ‚¨çš„å‘éŸ³å¾ˆæ£’ï¼")
        
        return "\n".join(feedback_parts)

class DetailedAnalyzer:
    """è¯¦ç»†åˆ†æå™¨ï¼Œæä¾›æ›´æ·±å…¥çš„éŸ³é«˜åˆ†æ"""
    
    def __init__(self):
        self.scoring_system = ScoringSystem()
    
    def analyze_pitch_details(self, comparison_result: dict) -> dict:
        """
        è¯¦ç»†åˆ†æéŸ³é«˜ç‰¹å¾
        :param comparison_result: éŸ³é«˜æ¯”è¾ƒç»“æœ
        :return: è¯¦ç»†åˆ†æç»“æœ
        """
        
        if 'error' in comparison_result:
            return {'error': comparison_result['error']}
        
        metrics = comparison_result.get('metrics', {})
        standard_pitch = comparison_result.get('standard_pitch', {})
        user_pitch = comparison_result.get('user_pitch', {})
        
        # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        analysis = {
            'duration_comparison': {
                'standard_duration': standard_pitch.get('duration', 0),
                'user_duration': user_pitch.get('duration', 0),
                'duration_ratio': self._safe_divide(
                    user_pitch.get('duration', 0),
                    standard_pitch.get('duration', 1)
                )
            },
            'pitch_statistics': {
                'standard': {
                    'mean': metrics.get('std_mean', 0),
                    'std': metrics.get('std_std', 0),
                    'valid_ratio': standard_pitch.get('valid_ratio', 0)
                },
                'user': {
                    'mean': metrics.get('user_mean', 0),
                    'std': metrics.get('user_std', 0),
                    'valid_ratio': user_pitch.get('valid_ratio', 0)
                }
            },
            'quality_assessment': self._assess_quality(standard_pitch, user_pitch),
            'alignment_info': comparison_result.get('aligned_data', {}).get('alignment_method', 'unknown')
        }
        
        return analysis
    
    def _safe_divide(self, a: float, b: float) -> float:
        """å®‰å…¨é™¤æ³•ï¼Œé¿å…é™¤é›¶é”™è¯¯"""
        return a / b if b != 0 else 0
    
    def _assess_quality(self, standard_pitch: dict, user_pitch: dict) -> dict:
        """è¯„ä¼°éŸ³é¢‘è´¨é‡"""
        
        std_quality = "è‰¯å¥½" if standard_pitch.get('valid_ratio', 0) > 0.7 else \
                     "ä¸€èˆ¬" if standard_pitch.get('valid_ratio', 0) > 0.4 else "è¾ƒå·®"
        
        user_quality = "è‰¯å¥½" if user_pitch.get('valid_ratio', 0) > 0.7 else \
                      "ä¸€èˆ¬" if user_pitch.get('valid_ratio', 0) > 0.4 else "è¾ƒå·®"
        
        return {
            'standard_quality': std_quality,
            'user_quality': user_quality,
            'recommendation': self._get_quality_recommendation(
                standard_pitch.get('valid_ratio', 0),
                user_pitch.get('valid_ratio', 0)
            )
        }
    
    def _get_quality_recommendation(self, std_ratio: float, user_ratio: float) -> str:
        """æ ¹æ®éŸ³é¢‘è´¨é‡ç»™å‡ºå»ºè®®"""
        if user_ratio < 0.4:
            return "å»ºè®®åœ¨å®‰é™ç¯å¢ƒä¸­é‡æ–°å½•éŸ³ï¼Œç¡®ä¿å£°éŸ³æ¸…æ™°"
        elif user_ratio < 0.7:
            return "å½•éŸ³è´¨é‡ä¸€èˆ¬ï¼Œå¯ä»¥å°è¯•é è¿‘éº¦å…‹é£æˆ–æé«˜éŸ³é‡"
        else:
            return "å½•éŸ³è´¨é‡è‰¯å¥½"

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # æµ‹è¯•è¯„åˆ†ç³»ç»Ÿ
    scoring_system = ScoringSystem()
    
    # æ¨¡æ‹Ÿæ¯”è¾ƒç»“æœ
    test_metrics = {
        'metrics': {
            'correlation': 0.75,
            'rmse': 35.0,
            'trend_consistency': 0.68,
            'pitch_range_ratio': 0.82,
            'std_mean': 200.0,
            'user_mean': 195.0,
            'std_std': 25.0,
            'user_std': 28.0
        }
    }
    
    # è®¡ç®—è¯„åˆ†
    score_result = scoring_system.calculate_score(test_metrics)
    
    print("=== è¯„åˆ†æµ‹è¯•ç»“æœ ===")
    print(f"æ€»åˆ†: {score_result['total_score']}")
    print(f"è¯„çº§: {score_result['level']}")
    print(f"å„é¡¹å¾—åˆ†: {score_result['component_scores']}")
    print(f"åé¦ˆå»ºè®®:\n{score_result['feedback']}")
