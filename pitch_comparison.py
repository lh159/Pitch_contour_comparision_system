# -*- coding: utf-8 -*-
"""
éŸ³é«˜æ¯”å¯¹ç®—æ³•æ¨¡å—
å®ç°éŸ³é«˜æ›²çº¿çš„æå–ã€å¯¹é½å’Œæ¯”è¾ƒåŠŸèƒ½
"""
import numpy as np
import parselmouth
from scipy import stats
from scipy.interpolate import interp1d
from scipy.ndimage import median_filter
from config import Config

try:
    from dtaidistance import dtw
    DTW_AVAILABLE = True
except ImportError:
    DTW_AVAILABLE = False
    print("è­¦å‘Š: DTWåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€å•çº¿æ€§å¯¹é½æ–¹æ³•")

try:
    from vad_module import VADComparator
    VAD_AVAILABLE = True
except ImportError:
    VAD_AVAILABLE = False
    print("è­¦å‘Š: VADæ¨¡å—æœªå¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»ŸéŸ³é«˜æ¯”å¯¹æ–¹æ³•")

try:
    from fun_asr_module import FunASRProcessor
    from visualization import PitchVisualizationWithFunASR
    FUN_ASR_AVAILABLE = True
except ImportError:
    FUN_ASR_AVAILABLE = False
    print("è­¦å‘Š: Fun-ASRæ¨¡å—æœªå¯ç”¨ï¼Œå°†ä½¿ç”¨æ ‡å‡†å¯è§†åŒ–æ–¹æ³•")

try:
    from enhanced_pitch_alignment import EnhancedPitchAligner
    ENHANCED_ALIGNMENT_AVAILABLE = True
except ImportError:
    ENHANCED_ALIGNMENT_AVAILABLE = False
    print("è­¦å‘Š: å¢å¼ºéŸ³é«˜å¯¹é½æ¨¡å—æœªå¯ç”¨ï¼Œå°†ä½¿ç”¨æ ‡å‡†å¯¹é½æ–¹æ³•")

class PitchExtractor:
    """éŸ³é«˜æå–å™¨"""
    
    def __init__(self):
        self.min_freq = Config.PITCH_MIN_FREQ
        self.max_freq = Config.PITCH_MAX_FREQ
        self.time_step = Config.PITCH_TIME_STEP
    
    def _normalize_audio_amplitude(self, sound: 'parselmouth.Sound') -> 'parselmouth.Sound':
        """
        éŸ³é¢‘ä¿¡å·æŒ¯å¹…å½’ä¸€åŒ–
        :param sound: åŸå§‹éŸ³é¢‘ä¿¡å·
        :return: å½’ä¸€åŒ–åçš„éŸ³é¢‘ä¿¡å·
        """
        try:
            # è·å–éŸ³é¢‘æ•°æ®
            values = sound.values[0]  # è·å–ç¬¬ä¸€ä¸ªå£°é“
            
            # è®¡ç®—RMS (å‡æ–¹æ ¹) èƒ½é‡
            rms = np.sqrt(np.mean(values**2))
            
            if rms > 0:
                # å½’ä¸€åŒ–åˆ°ç›®æ ‡RMSæ°´å¹³ (çº¦-20dB)
                target_rms = 0.1
                scaling_factor = target_rms / rms
                
                # åº”ç”¨ç¼©æ”¾ï¼Œä½†é¿å…è¿‡åº¦æ”¾å¤§
                scaling_factor = min(scaling_factor, 5.0)  # æœ€å¤§æ”¾å¤§5å€
                normalized_values = values * scaling_factor
                
                # é˜²æ­¢å‰Šæ³¢ (clipping)
                max_val = np.max(np.abs(normalized_values))
                if max_val > 0.95:
                    normalized_values = normalized_values * (0.95 / max_val)
                
                # åˆ›å»ºæ–°çš„Soundå¯¹è±¡
                normalized_sound = parselmouth.Sound(
                    normalized_values, 
                    sampling_frequency=sound.sampling_frequency
                )
                return normalized_sound
            else:
                return sound
                
        except Exception as e:
            print(f"éŸ³é¢‘æŒ¯å¹…å½’ä¸€åŒ–å¤±è´¥: {e}")
            return sound
    
    def _enhance_audio_quality(self, sound: 'parselmouth.Sound') -> 'parselmouth.Sound':
        """
        éŸ³é¢‘è´¨é‡å¢å¼ºï¼šé™å™ªå’Œé¢„åŠ é‡
        :param sound: è¾“å…¥éŸ³é¢‘
        :return: å¢å¼ºåçš„éŸ³é¢‘
        """
        try:
            # 1. é¢„åŠ é‡æ»¤æ³¢ (æå‡é«˜é¢‘ï¼Œæ”¹å–„éŸ³é«˜æ£€æµ‹)
            preemphasized = sound.copy()
            values = preemphasized.values[0]
            
            # åº”ç”¨é¢„åŠ é‡æ»¤æ³¢å™¨ y[n] = x[n] - 0.97*x[n-1]
            preemph_coeff = 0.97
            for i in range(1, len(values)):
                values[i] = values[i] - preemph_coeff * values[i-1]
            
            # 2. ç®€å•çš„å™ªå£°é—¨é™ (å»é™¤è¿‡å°çš„ä¿¡å·)
            # è®¡ç®—ä¿¡å·çš„åŠ¨æ€èŒƒå›´
            signal_max = np.max(np.abs(values))
            noise_floor = signal_max * 0.01  # å™ªå£°é—¨é™è®¾ä¸ºæœ€å¤§å€¼çš„1%
            
            # åº”ç”¨å™ªå£°é—¨é™
            values[np.abs(values) < noise_floor] *= 0.1
            
            enhanced_sound = parselmouth.Sound(
                values,
                sampling_frequency=sound.sampling_frequency
            )
            return enhanced_sound
            
        except Exception as e:
            print(f"éŸ³é¢‘è´¨é‡å¢å¼ºå¤±è´¥: {e}")
            return sound
    
    def _aggressive_audio_enhancement(self, sound: 'parselmouth.Sound') -> 'parselmouth.Sound':
        """
        æ¿€è¿›çš„éŸ³é¢‘å¢å¼ºï¼Œç”¨äºå¤„ç†æä½è´¨é‡çš„æ‰‹æœºå½•éŸ³
        :param sound: è¾“å…¥éŸ³é¢‘
        :return: æ¿€è¿›å¢å¼ºåçš„éŸ³é¢‘
        """
        try:
            enhanced = sound.copy()
            values = enhanced.values[0]
            
            # 1. æ›´å¼ºçš„é¢„åŠ é‡
            preemph_coeff = 0.95  # æ›´å¼ºçš„é¢„åŠ é‡
            for i in range(1, len(values)):
                values[i] = values[i] - preemph_coeff * values[i-1]
            
            # 2. åŠ¨æ€èŒƒå›´å‹ç¼© (å‹ç¼©å™¨)
            # è®¡ç®—çŸ­æ—¶èƒ½é‡
            frame_size = int(enhanced.sampling_frequency * 0.025)  # 25msçª—å£
            hop_size = frame_size // 2
            
            for i in range(0, len(values) - frame_size, hop_size):
                frame = values[i:i+frame_size]
                rms = np.sqrt(np.mean(frame**2))
                
                if rms > 0:
                    # å‹ç¼©å™¨ï¼šå¼ºä¿¡å·å‹ç¼©ï¼Œå¼±ä¿¡å·æ”¾å¤§
                    threshold = 0.1
                    ratio = 4.0  # 4:1å‹ç¼©æ¯”
                    
                    if rms > threshold:
                        # å‹ç¼©å¼ºä¿¡å·
                        compressed_rms = threshold + (rms - threshold) / ratio
                    else:
                        # æ”¾å¤§å¼±ä¿¡å·
                        compressed_rms = rms * 2.0
                    
                    gain = compressed_rms / rms
                    values[i:i+frame_size] *= gain
            
            # 3. é«˜é€šæ»¤æ³¢å»é™¤ä½é¢‘å™ªéŸ³
            # ç®€å•çš„é«˜é€šæ»¤æ³¢å™¨ï¼ˆå»é™¤50Hzä»¥ä¸‹ï¼‰
            sampling_rate = enhanced.sampling_frequency
            cutoff = 50.0  # Hz
            
            # ä¸€é˜¶é«˜é€šæ»¤æ³¢å™¨ç³»æ•°
            rc = 1.0 / (2 * np.pi * cutoff)
            dt = 1.0 / sampling_rate
            alpha = rc / (rc + dt)
            
            # åº”ç”¨é«˜é€šæ»¤æ³¢
            filtered_values = np.zeros_like(values)
            filtered_values[0] = values[0]
            for i in range(1, len(values)):
                filtered_values[i] = alpha * (filtered_values[i-1] + values[i] - values[i-1])
            
            # 4. è‡ªåŠ¨å¢ç›Šæ§åˆ¶
            target_rms = 0.15
            current_rms = np.sqrt(np.mean(filtered_values**2))
            if current_rms > 0:
                auto_gain = min(target_rms / current_rms, 8.0)  # æœ€å¤§æ”¾å¤§8å€
                filtered_values *= auto_gain
            
            # 5. è½¯é™å¹…é˜²æ­¢å‰Šæ³¢
            max_val = np.max(np.abs(filtered_values))
            if max_val > 0.9:
                # è½¯é™å¹…
                filtered_values = np.tanh(filtered_values * 0.9 / max_val) * 0.9
            
            enhanced_sound = parselmouth.Sound(
                filtered_values,
                sampling_frequency=enhanced.sampling_frequency
            )
            return enhanced_sound
            
        except Exception as e:
            print(f"æ¿€è¿›éŸ³é¢‘å¢å¼ºå¤±è´¥: {e}")
            return sound
    
    def _load_audio_with_format_detection(self, audio_path: str) -> 'parselmouth.Sound':
        """
        å¸¦æ ¼å¼æ£€æµ‹çš„éŸ³é¢‘åŠ è½½ï¼Œå¤„ç†WebMç­‰æ ¼å¼é—®é¢˜
        :param audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :return: parselmouth Soundå¯¹è±¡
        """
        import os
        import subprocess
        
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥åŠ è½½
            return parselmouth.Sound(audio_path)
        except Exception as e:
            print(f"ç›´æ¥åŠ è½½å¤±è´¥: {e}ï¼Œå°è¯•æ ¼å¼æ£€æµ‹å’Œè½¬æ¢...")
            
            # æ£€æŸ¥æ–‡ä»¶å¤´ç¡®å®šå®é™…æ ¼å¼
            actual_format = None
            try:
                with open(audio_path, 'rb') as f:
                    header = f.read(16)
                    if header[:4] == b'\x1a\x45\xdf\xa3':  # WebM/Matroskaæ–‡ä»¶å¤´
                        actual_format = 'webm'
                        print("âš ï¸ æ£€æµ‹åˆ°WebMæ ¼å¼æ–‡ä»¶ï¼Œä½†æ‰©å±•åå¯èƒ½ä¸æ­£ç¡®")
                    elif header[:4] == b'ftyp':  # MP4æ–‡ä»¶å¤´
                        actual_format = 'mp4'
                    elif header[:2] == b'\xff\xfb' or header[:2] == b'\xff\xf3':  # MP3æ–‡ä»¶å¤´
                        actual_format = 'mp3'
            except Exception as header_e:
                print(f"æ–‡ä»¶å¤´æ£€æµ‹å¤±è´¥: {header_e}")
            
            if actual_format:
                # ç”Ÿæˆä¸´æ—¶è½¬æ¢æ–‡ä»¶
                temp_wav_path = audio_path.replace('.wav', '_temp_converted.wav')
                
                try:
                    # ä½¿ç”¨ffmpegè½¬æ¢
                    if actual_format == 'webm':
                        ffmpeg_cmd = [
                            'ffmpeg', '-f', 'webm', '-i', audio_path,
                            '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1',
                            '-y', temp_wav_path
                        ]
                    elif actual_format == 'mp4':
                        ffmpeg_cmd = [
                            'ffmpeg', '-f', 'mp4', '-i', audio_path,
                            '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1',
                            '-y', temp_wav_path
                        ]
                    elif actual_format == 'mp3':
                        ffmpeg_cmd = [
                            'ffmpeg', '-f', 'mp3', '-i', audio_path,
                            '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1',
                            '-y', temp_wav_path
                        ]
                    
                    result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True, timeout=30)
                    
                    if result.returncode == 0 and os.path.exists(temp_wav_path):
                        print(f"âœ… æ ¼å¼è½¬æ¢æˆåŠŸ: {actual_format} -> WAV")
                        try:
                            # åŠ è½½è½¬æ¢åçš„æ–‡ä»¶
                            sound = parselmouth.Sound(temp_wav_path)
                            
                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            if os.path.exists(temp_wav_path):
                                os.remove(temp_wav_path)
                            
                            return sound
                        except Exception as load_e:
                            print(f"è½¬æ¢åæ–‡ä»¶åŠ è½½å¤±è´¥: {load_e}")
                            if os.path.exists(temp_wav_path):
                                os.remove(temp_wav_path)
                    else:
                        print(f"ffmpegè½¬æ¢å¤±è´¥: {result.stderr}")
                        
                except subprocess.TimeoutExpired:
                    print("ffmpegè½¬æ¢è¶…æ—¶")
                except Exception as conv_e:
                    print(f"è½¬æ¢è¿‡ç¨‹å‡ºé”™: {conv_e}")
            
            # å¦‚æœæ‰€æœ‰è½¬æ¢å°è¯•éƒ½å¤±è´¥ï¼Œé‡æ–°æŠ›å‡ºåŸå§‹å¼‚å¸¸
            raise e
    
    def extract_pitch(self, audio_path: str) -> dict:
        """
        ä»éŸ³é¢‘æ–‡ä»¶ä¸­æå–éŸ³é«˜æ›²çº¿
        :param audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :return: åŒ…å«éŸ³é«˜æ•°æ®çš„å­—å…¸
        """
        try:
            # åŠ è½½éŸ³é¢‘
            if isinstance(audio_path, str):
                # ğŸ”§ æ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼Œå¤„ç†WebMä¼ªè£…æˆWAVçš„é—®é¢˜
                snd = self._load_audio_with_format_detection(audio_path)
            else:
                # å¦‚æœæ˜¯Soundå¯¹è±¡ç›´æ¥ä½¿ç”¨
                snd = audio_path
            
            # ğŸ”§ éŸ³é¢‘é¢„å¤„ç†ï¼šå½’ä¸€åŒ–å’Œè´¨é‡å¢å¼º
            snd = self._normalize_audio_amplitude(snd)
            snd = self._enhance_audio_quality(snd)
            
            # ğŸ¯ ä¼˜åŒ–æ‰‹æœºå½•éŸ³çš„éŸ³é«˜æå–å‚æ•°
            # ä½¿ç”¨æ›´å®½å®¹çš„å‚æ•°è®¾ç½®ï¼Œé€‚åº”æ‰‹æœºå½•éŸ³ç‰¹ç‚¹
            pitch = snd.to_pitch(
                pitch_floor=self.min_freq,
                pitch_ceiling=self.max_freq,
                time_step=self.time_step,
                very_accurate=False,  # ç¦ç”¨æé«˜ç²¾åº¦æ¨¡å¼ï¼Œæé«˜å®¹é”™æ€§
                max_number_of_candidates=15,  # å¢åŠ å€™é€‰éŸ³é«˜æ•°é‡
                silence_threshold=0.03,  # é™ä½é™éŸ³é˜ˆå€¼
                voicing_threshold=0.45,  # é™ä½æœ‰å£°æ£€æµ‹é˜ˆå€¼ï¼ˆé»˜è®¤0.5ï¼‰
                octave_cost=0.01,  # é™ä½å…«åº¦è·³è·ƒæƒ©ç½š
                octave_jump_cost=0.35,  # é™ä½å…«åº¦è·³è·ƒæˆæœ¬
                voiced_unvoiced_cost=0.14  # é™ä½æœ‰å£°/æ— å£°åˆ‡æ¢æˆæœ¬
            )
            
            # è·å–éŸ³é«˜å€¼å’Œæ—¶é—´è½´
            pitch_values = pitch.selected_array['frequency']
            times = pitch.xs()
            
            # å¤„ç†æ— å£°æ®µï¼ˆ0Hz -> NaNï¼‰
            pitch_values[pitch_values == 0] = np.nan
            
            # è®¡ç®—åˆå§‹æœ‰æ•ˆæ¯”ä¾‹
            initial_valid_ratio = np.sum(~np.isnan(pitch_values)) / len(pitch_values) if len(pitch_values) > 0 else 0
            
            # ğŸ¯ å¦‚æœéŸ³é«˜æ£€æµ‹æ•ˆæœå¾ˆå·®ï¼Œå°è¯•æ›´æ¿€è¿›çš„éŸ³é¢‘å¢å¼º
            if initial_valid_ratio < 0.05:
                print(f"âš ï¸ åˆå§‹éŸ³é«˜æ£€æµ‹æ•ˆæœå·®({initial_valid_ratio:.1%})ï¼Œå°è¯•å¢å¼ºéŸ³é¢‘...")
                
                # æ›´æ¿€è¿›çš„éŸ³é¢‘å¢å¼º
                enhanced_snd = self._aggressive_audio_enhancement(snd)
                
                # é‡æ–°æå–éŸ³é«˜ï¼Œä½¿ç”¨æ›´å®½æ¾çš„å‚æ•°
                retry_pitch = enhanced_snd.to_pitch(
                    pitch_floor=max(50, self.min_freq - 30),  # è¿›ä¸€æ­¥é™ä½éŸ³é«˜ä¸‹é™
                    pitch_ceiling=min(800, self.max_freq + 100),  # æé«˜éŸ³é«˜ä¸Šé™
                    time_step=self.time_step * 0.8,  # å¢åŠ æ—¶é—´åˆ†è¾¨ç‡
                    very_accurate=False,
                    max_number_of_candidates=20,
                    silence_threshold=0.02,  # æ›´ä½çš„é™éŸ³é˜ˆå€¼
                    voicing_threshold=0.35,  # æ›´ä½çš„æœ‰å£°æ£€æµ‹é˜ˆå€¼
                    octave_cost=0.005,
                    octave_jump_cost=0.25,
                    voiced_unvoiced_cost=0.1
                )
                
                retry_pitch_values = retry_pitch.selected_array['frequency']
                retry_pitch_values[retry_pitch_values == 0] = np.nan
                retry_valid_ratio = np.sum(~np.isnan(retry_pitch_values)) / len(retry_pitch_values) if len(retry_pitch_values) > 0 else 0
                
                # å¦‚æœé‡è¯•æ•ˆæœæ›´å¥½ï¼Œä½¿ç”¨é‡è¯•ç»“æœ
                if retry_valid_ratio > initial_valid_ratio:
                    print(f"âœ“ éŸ³é¢‘å¢å¼ºæˆåŠŸï¼Œæœ‰æ•ˆæ¯”ä¾‹ä»{initial_valid_ratio:.1%}æå‡åˆ°{retry_valid_ratio:.1%}")
                    pitch_values = retry_pitch_values
                    times = retry_pitch.xs()
                    initial_valid_ratio = retry_valid_ratio
            
            # ğŸ¯ ä¿ç•™åŸå§‹éŸ³é«˜æ›²çº¿ï¼Œä¸è¿›è¡Œå¹³æ»‘å¤„ç†
            # è®©æ›²çº¿åæ˜ å½’ä¸€åŒ–åçš„çœŸå®è¯­éŸ³ç‰¹å¾
            
            return {
                'times': times,
                'pitch_values': pitch_values,
                'smooth_pitch': pitch_values,  # ä½¿ç”¨åŸå§‹å€¼ï¼Œä¿æŒæ¥å£å…¼å®¹æ€§
                'duration': times[-1] if len(times) > 0 else 0,
                'valid_ratio': initial_valid_ratio
            }
            
        except Exception as e:
            print(f"éŸ³é«˜æå–å¤±è´¥: {e}")
            return {
                'times': np.array([]),
                'pitch_values': np.array([]),
                'smooth_pitch': np.array([]),
                'duration': 0,
                'valid_ratio': 0
            }
    
    def _smooth_pitch(self, pitch_values: np.ndarray, window_size: int = 3) -> np.ndarray:
        """
        å¹³æ»‘éŸ³é«˜æ›²çº¿ï¼Œå»é™¤å™ªå£°
        :param pitch_values: åŸå§‹éŸ³é«˜å€¼
        :param window_size: å¹³æ»‘çª—å£å¤§å°
        :return: å¹³æ»‘åçš„éŸ³é«˜å€¼
        """
        if len(pitch_values) == 0:
            return pitch_values
        
        # å¯¹æœ‰æ•ˆå€¼è¿›è¡Œä¸­å€¼æ»¤æ³¢
        smooth_pitch = pitch_values.copy()
        valid_mask = ~np.isnan(pitch_values)
        
        if np.sum(valid_mask) > window_size:
            # åªå¯¹æœ‰æ•ˆéƒ¨åˆ†è¿›è¡Œå¹³æ»‘
            valid_indices = np.where(valid_mask)[0]
            valid_values = pitch_values[valid_mask]
            
            # ä¸­å€¼æ»¤æ³¢
            smoothed_valid = median_filter(valid_values, size=window_size)
            smooth_pitch[valid_indices] = smoothed_valid
        
        return smooth_pitch

class PitchAligner:
    """éŸ³é«˜æ›²çº¿å¯¹é½å™¨"""
    
    def __init__(self):
        self.use_dtw = DTW_AVAILABLE
    
    def align_pitch_curves(self, standard_pitch: dict, user_pitch: dict) -> dict:
        """
        å¯¹é½ä¸¤ä¸ªéŸ³é«˜æ›²çº¿
        :param standard_pitch: æ ‡å‡†å‘éŸ³çš„éŸ³é«˜æ•°æ®
        :param user_pitch: ç”¨æˆ·å‘éŸ³çš„éŸ³é«˜æ•°æ®
        :return: å¯¹é½åçš„éŸ³é«˜æ•°æ®
        """
        
        # æå–æœ‰æ•ˆçš„éŸ³é«˜æ•°æ®
        std_times = standard_pitch['times']
        std_pitch = standard_pitch['smooth_pitch']
        user_times = user_pitch['times']
        user_pitch_values = user_pitch['smooth_pitch']
        
        if len(std_pitch) == 0 or len(user_pitch_values) == 0:
            return {
                'aligned_standard': np.array([]),
                'aligned_user': np.array([]),
                'aligned_times': np.array([]),
                'alignment_method': 'none'
            }
        
        # é€‰æ‹©å¯¹é½æ–¹æ³•
        if self.use_dtw and len(std_pitch) > 10 and len(user_pitch_values) > 10:
            return self._dtw_align(std_times, std_pitch, user_times, user_pitch_values)
        else:
            return self._linear_align(std_times, std_pitch, user_times, user_pitch_values)
    
    def _dtw_align(self, std_times: np.ndarray, std_pitch: np.ndarray, 
                   user_times: np.ndarray, user_pitch: np.ndarray) -> dict:
        """ä½¿ç”¨DTWç®—æ³•è¿›è¡Œæ—¶é—´å¯¹é½"""
        
        # é¢„å¤„ç†ï¼šå»é™¤NaNå€¼å¹¶æ’å€¼
        std_clean = self._interpolate_nan(std_pitch)
        user_clean = self._interpolate_nan(user_pitch)
        
        if len(std_clean) == 0 or len(user_clean) == 0:
            return self._linear_align(std_times, std_pitch, user_times, user_pitch)
        
        try:
            # å½’ä¸€åŒ–éŸ³é«˜å€¼ä»¥æé«˜DTWæ•ˆæœ
            std_norm = self._normalize_pitch(std_clean)
            user_norm = self._normalize_pitch(user_clean)
            
            # æ‰§è¡ŒDTWå¯¹é½
            path = dtw.warping_path(std_norm, user_norm)
            
            # æ ¹æ®å¯¹é½è·¯å¾„é‡æ–°é‡‡æ ·
            aligned_length = len(path)
            aligned_times = np.linspace(0, max(std_times[-1], user_times[-1]), aligned_length)
            
            # æå–å¯¹é½åçš„åºåˆ—
            aligned_standard = np.array([std_clean[i] for i, j in path])
            aligned_user = np.array([user_clean[j] for i, j in path])
            
            # ğŸ¯ åº”ç”¨éŸ³é«˜åŸºçº¿å¯¹é½
            aligned_standard, aligned_user = self._align_pitch_baseline(aligned_standard, aligned_user)
            
            return {
                'aligned_standard': aligned_standard,
                'aligned_user': aligned_user,
                'aligned_times': aligned_times,
                'alignment_method': 'dtw'
            }
            
        except Exception as e:
            print(f"DTWå¯¹é½å¤±è´¥ï¼Œä½¿ç”¨çº¿æ€§å¯¹é½: {e}")
            return self._linear_align(std_times, std_pitch, user_times, user_pitch)
    
    def _linear_align(self, std_times: np.ndarray, std_pitch: np.ndarray,
                      user_times: np.ndarray, user_pitch: np.ndarray) -> dict:
        """ä½¿ç”¨çº¿æ€§æ’å€¼è¿›è¡Œç®€å•å¯¹é½"""
        
        # ç¡®å®šç»Ÿä¸€çš„æ—¶é—´è½´
        max_duration = max(std_times[-1] if len(std_times) > 0 else 0,
                          user_times[-1] if len(user_times) > 0 else 0)
        
        if max_duration == 0:
            return {
                'aligned_standard': np.array([]),
                'aligned_user': np.array([]),
                'aligned_times': np.array([]),
                'alignment_method': 'linear'
            }
        
        # åˆ›å»ºç»Ÿä¸€æ—¶é—´è½´
        aligned_times = np.linspace(0, max_duration, 
                                   max(len(std_times), len(user_times), 100))
        
        # æ’å€¼åˆ°ç»Ÿä¸€æ—¶é—´è½´
        try:
            aligned_standard = self._interpolate_to_timeline(
                std_times, std_pitch, aligned_times)
            aligned_user = self._interpolate_to_timeline(
                user_times, user_pitch, aligned_times)
            
            # ğŸ¯ åº”ç”¨éŸ³é«˜åŸºçº¿å¯¹é½
            aligned_standard, aligned_user = self._align_pitch_baseline(aligned_standard, aligned_user)
            
            return {
                'aligned_standard': aligned_standard,
                'aligned_user': aligned_user,
                'aligned_times': aligned_times,
                'alignment_method': 'linear'
            }
        except Exception as e:
            print(f"çº¿æ€§å¯¹é½å¤±è´¥: {e}")
            return {
                'aligned_standard': np.array([]),
                'aligned_user': np.array([]),
                'aligned_times': np.array([]),
                'alignment_method': 'failed'
            }
    
    def _interpolate_nan(self, pitch_values: np.ndarray) -> np.ndarray:
        """æ’å€¼å¡«è¡¥NaNå€¼"""
        if len(pitch_values) == 0:
            return pitch_values
        
        # æ‰¾åˆ°æœ‰æ•ˆå€¼
        valid_mask = ~np.isnan(pitch_values)
        if np.sum(valid_mask) < 2:
            return np.array([])
        
        # çº¿æ€§æ’å€¼å¡«è¡¥NaN
        x = np.arange(len(pitch_values))
        valid_x = x[valid_mask]
        valid_y = pitch_values[valid_mask]
        
        # åˆ›å»ºæ’å€¼å‡½æ•°
        f = interp1d(valid_x, valid_y, kind='linear', 
                    bounds_error=False, fill_value='extrapolate')
        
        # æ’å€¼
        interpolated = f(x)
        
        return interpolated
    
    def _normalize_pitch(self, pitch_values: np.ndarray) -> np.ndarray:
        """å½’ä¸€åŒ–éŸ³é«˜å€¼ (ç”¨äºDTWå¯¹é½)"""
        if len(pitch_values) == 0:
            return pitch_values
        
        mean_pitch = np.mean(pitch_values)
        std_pitch = np.std(pitch_values)
        
        if std_pitch == 0:
            return pitch_values - mean_pitch
        
        return (pitch_values - mean_pitch) / std_pitch
    
    def _align_pitch_baseline(self, standard: np.ndarray, user: np.ndarray) -> tuple:
        """
        æ™ºèƒ½éŸ³é«˜åŸºçº¿å¯¹é½ï¼šåŸºäºä¸­æ–‡å£°è°ƒç‰¹å¾çš„ä¼˜åŒ–å¯¹é½ç®—æ³•
        :param standard: æ ‡å‡†éŸ³é«˜æ›²çº¿
        :param user: ç”¨æˆ·éŸ³é«˜æ›²çº¿  
        :return: å¯¹é½åçš„ (æ ‡å‡†éŸ³é«˜, ç”¨æˆ·éŸ³é«˜)
        """
        try:
            # è¿‡æ»¤æœ‰æ•ˆå€¼
            std_valid = standard[~np.isnan(standard)]
            user_valid = user[~np.isnan(user)]
            
            if len(std_valid) < 5 or len(user_valid) < 5:
                return standard, user
            
            # ğŸ¯ ä½¿ç”¨ç»Ÿè®¡åˆ†æç¡®å®šåŸºçº¿å’Œå˜åŒ–èŒƒå›´
            std_stats = self._calculate_pitch_statistics(std_valid)
            user_stats = self._calculate_pitch_statistics(user_valid)
            
            # è®¡ç®—åŸºçº¿å·®å¼‚ - ä½¿ç”¨å¤šç§ç»Ÿè®¡é‡çš„ç»¼åˆè¯„ä¼°
            baseline_diff = user_stats['median'] - std_stats['median']
            mean_diff = user_stats['mean'] - std_stats['mean']
            
            # ğŸµ åˆ†æéŸ³é«˜å˜åŒ–å¹…åº¦ - ç”¨äºä¿ç•™å£°è°ƒç‰¹å¾
            std_range = std_stats['p75'] - std_stats['p25']  # å››åˆ†ä½è·
            user_range = user_stats['p75'] - user_stats['p25']
            
            # ğŸ” æ™ºèƒ½é˜ˆå€¼ï¼šåŸºäºéŸ³é«˜èŒƒå›´åŠ¨æ€è°ƒæ•´
            adaptive_threshold = max(30, min(80, std_range * 0.4))
            
            if abs(baseline_diff) > adaptive_threshold:
                # ğŸ¶ å£°è°ƒæ„ŸçŸ¥çš„å¯¹é½ç­–ç•¥
                scale_factor = self._calculate_optimal_scale_factor(
                    std_stats, user_stats, baseline_diff
                )
                
                # ğŸ“Š ç›¸å¯¹éŸ³é«˜å¯¹é½ï¼šä¿æŒéŸ³è°ƒå˜åŒ–æ¯”ä¾‹
                if abs(baseline_diff) > abs(mean_diff) * 1.5:
                    # å­˜åœ¨æ˜æ˜¾ç³»ç»Ÿæ€§åå·®ï¼ˆå¦‚æ€§åˆ«å·®å¼‚ï¼‰
                    aligned_user = self._apply_relative_alignment(
                        user, std_stats, user_stats, scale_factor
                    )
                    aligned_standard = standard
                    
                    print(f"ğŸµ æ™ºèƒ½åŸºçº¿å¯¹é½: å·®å¼‚{baseline_diff:.1f}Hzï¼Œ"
                          f"ç¼©æ”¾å› å­{scale_factor:.3f}ï¼Œä¿æŒå£°è°ƒç‰¹å¾")
                else:
                    # è½»å¾®è°ƒæ•´ï¼Œä¸»è¦ä¿æŒåŸæœ‰ç‰¹å¾
                    adjustment = baseline_diff * 0.5  # æ›´ä¿å®ˆçš„è°ƒæ•´
                    aligned_user = user - adjustment
                    aligned_standard = standard
                    
                    print(f"ğŸ¶ è½»åº¦åŸºçº¿è°ƒæ•´: {adjustment:.1f}Hz")
                
                return aligned_standard, aligned_user
            else:
                # å·®å¼‚åœ¨å¯æ¥å—èŒƒå›´å†…ï¼Œä¿æŒåŸæ ·
                return standard, user
                
        except Exception as e:
            print(f"æ™ºèƒ½éŸ³é«˜åŸºçº¿å¯¹é½å¤±è´¥: {e}")
            return standard, user
    
    def _calculate_pitch_statistics(self, pitch_values: np.ndarray) -> dict:
        """è®¡ç®—éŸ³é«˜çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'mean': np.mean(pitch_values),
            'median': np.median(pitch_values),
            'std': np.std(pitch_values),
            'p25': np.percentile(pitch_values, 25),
            'p75': np.percentile(pitch_values, 75),
            'min': np.min(pitch_values),
            'max': np.max(pitch_values),
            'range': np.max(pitch_values) - np.min(pitch_values)
        }
    
    def _calculate_optimal_scale_factor(self, std_stats: dict, user_stats: dict, 
                                      baseline_diff: float) -> float:
        """è®¡ç®—æœ€ä¼˜ç¼©æ”¾å› å­ï¼Œå¹³è¡¡åŸºçº¿å¯¹é½å’Œå£°è°ƒä¿æŒ"""
        # åŸºäºéŸ³é«˜èŒƒå›´çš„æ™ºèƒ½ç¼©æ”¾
        std_range = std_stats['range']
        user_range = user_stats['range']
        
        if std_range > 0 and user_range > 0:
            # è€ƒè™‘éŸ³é«˜èŒƒå›´æ¯”ä¾‹
            range_ratio = user_range / std_range
            # åŸºçº¿å·®å¼‚çš„ç›¸å¯¹å¤§å°
            relative_diff = abs(baseline_diff) / std_range
            
            # æ™ºèƒ½ç¼©æ”¾ï¼šå·®å¼‚è¶Šå¤§ï¼Œè°ƒæ•´è¶Šä¿å®ˆ
            if relative_diff > 0.5:  # å¤§å·®å¼‚
                return 0.3 + 0.2 * (1 / (1 + relative_diff))
            else:  # å°å·®å¼‚
                return 0.6 + 0.3 * (1 - relative_diff)
        else:
            return 0.5  # é»˜è®¤ä¸­ç­‰è°ƒæ•´
    
    def _apply_relative_alignment(self, user_pitch: np.ndarray, std_stats: dict, 
                                user_stats: dict, scale_factor: float) -> np.ndarray:
        """åº”ç”¨ç›¸å¯¹éŸ³é«˜å¯¹é½ï¼Œä¿æŒå£°è°ƒå˜åŒ–æ¯”ä¾‹"""
        # è®¡ç®—ç”¨æˆ·éŸ³é«˜ç›¸å¯¹äºå…¶åŸºçº¿çš„åå·®
        user_baseline = user_stats['median']
        relative_pitch = user_pitch - user_baseline
        
        # ç›®æ ‡åŸºçº¿
        target_baseline = std_stats['median']
        
        # åº”ç”¨ç¼©æ”¾å’Œå¹³ç§»
        aligned_pitch = target_baseline + relative_pitch * scale_factor
        
        return aligned_pitch
    
    def _interpolate_to_timeline(self, times: np.ndarray, values: np.ndarray, 
                                target_times: np.ndarray) -> np.ndarray:
        """æ’å€¼åˆ°ç›®æ ‡æ—¶é—´è½´"""
        if len(times) == 0 or len(values) == 0:
            return np.full(len(target_times), np.nan)
        
        # åªä½¿ç”¨æœ‰æ•ˆå€¼è¿›è¡Œæ’å€¼
        valid_mask = ~np.isnan(values)
        if np.sum(valid_mask) < 2:
            return np.full(len(target_times), np.nan)
        
        valid_times = times[valid_mask]
        valid_values = values[valid_mask]
        
        # åˆ›å»ºæ’å€¼å‡½æ•°
        f = interp1d(valid_times, valid_values, kind='linear',
                    bounds_error=False, fill_value=np.nan)
        
        return f(target_times)

class PitchComparator:
    """éŸ³é«˜æ›²çº¿æ¯”è¾ƒå™¨"""
    
    def __init__(self):
        self.extractor = PitchExtractor()
        self.aligner = PitchAligner()
        
        # é›†æˆVADåŠŸèƒ½
        self.vad_comparator = None
        self.use_vad = Config.VAD_ENABLED and VAD_AVAILABLE
        
        if self.use_vad:
            try:
                self.vad_comparator = VADComparator()
                print("âœ“ VADå¢å¼ºåŠŸèƒ½å·²å¯ç”¨")
            except Exception as e:
                print(f"âš ï¸ VADåŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
                self.use_vad = False
        
        # é›†æˆFun-ASRåŠŸèƒ½
        self.fun_asr_processor = None
        self.use_fun_asr = FUN_ASR_AVAILABLE
        
        if self.use_fun_asr:
            try:
                self.fun_asr_processor = FunASRProcessor()
                print("âœ“ Fun-ASRæ—¶é—´æˆ³åŠŸèƒ½å·²å¯ç”¨")
            except Exception as e:
                print(f"âš ï¸ Fun-ASRåŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
                self.use_fun_asr = False
        
        # ğŸš€ é›†æˆå¢å¼ºéŸ³é«˜å¯¹é½åŠŸèƒ½
        self.enhanced_aligner = None
        self.use_enhanced_alignment = ENHANCED_ALIGNMENT_AVAILABLE
        
        if self.use_enhanced_alignment:
            try:
                self.enhanced_aligner = EnhancedPitchAligner()
                print("âœ“ å¢å¼ºéŸ³é«˜å¯¹é½åŠŸèƒ½å·²å¯ç”¨")
            except Exception as e:
                print(f"âš ï¸ å¢å¼ºéŸ³é«˜å¯¹é½åŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
                self.use_enhanced_alignment = False
    
    def compare_pitch_curves(self, standard_audio: str, user_audio: str, 
                           expected_text: str = None, enable_text_alignment: bool = True) -> dict:
        """
        æ¯”è¾ƒä¸¤ä¸ªéŸ³é¢‘çš„éŸ³é«˜æ›²çº¿ - å¢å¼ºç‰ˆæœ¬
        :param standard_audio: æ ‡å‡†å‘éŸ³éŸ³é¢‘è·¯å¾„
        :param user_audio: ç”¨æˆ·å‘éŸ³éŸ³é¢‘è·¯å¾„
        :param expected_text: æœŸæœ›çš„æ–‡æœ¬ï¼ˆç”¨äºæ–‡æœ¬å¯¹é½ï¼‰
        :param enable_text_alignment: æ˜¯å¦å¯ç”¨æ–‡æœ¬å¯¹é½åŠŸèƒ½
        :return: æ¯”è¾ƒç»“æœ
        """
        vad_result = None
        actual_standard_audio = standard_audio
        actual_user_audio = user_audio
        enhanced_alignment_result = None
        
        # ğŸš€ ä½¿ç”¨å¢å¼ºéŸ³é«˜å¯¹é½ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.use_enhanced_alignment and self.enhanced_aligner and expected_text:
            print("ğŸ¯ æ‰§è¡Œå¢å¼ºéŸ³é«˜å¯¹é½åˆ†æ...")
            
            try:
                # 1. éªŒè¯ç”¨æˆ·å½•éŸ³è´¨é‡
                user_quality = self.enhanced_aligner.validate_user_audio_quality(user_audio)
                if not user_quality['is_valid']:
                    return {
                        'error': f"ç”¨æˆ·å½•éŸ³è´¨é‡é—®é¢˜: {user_quality['reason']}",
                        'details': user_quality['details'],
                        'suggestion': 'è¯·é‡æ–°å½•éŸ³ï¼Œç¡®ä¿æ¸…æ™°å‘éŸ³å¹¶é¿å…èƒŒæ™¯å™ªéŸ³'
                    }
                
                # 2. è·å–TTSæœ‰æ•ˆæ—¶é•¿
                tts_duration = self.enhanced_aligner.get_tts_audio_duration(standard_audio, expected_text)
                
                # 3. ASRæ—¶é—´è½´å¯¹é½
                alignment_result = self.enhanced_aligner.align_user_audio_with_tts(
                    user_audio, standard_audio, expected_text
                )
                
                if alignment_result['success']:
                    enhanced_alignment_result = alignment_result
                    print(f"âœ“ å¢å¼ºå¯¹é½æˆåŠŸï¼ŒTTSæœ‰æ•ˆæ—¶é•¿: {tts_duration:.3f}s")
                else:
                    print(f"âš ï¸ å¢å¼ºå¯¹é½å¤±è´¥: {alignment_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
            except Exception as e:
                print(f"âš ï¸ å¢å¼ºå¯¹é½å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†å¤„ç†: {e}")
        
        # 1. VADé¢„å¤„ç†ï¼ˆå¦‚æœå¯ç”¨ä¸”æ²¡æœ‰ä½¿ç”¨å¢å¼ºå¯¹é½ï¼‰
        if not enhanced_alignment_result and self.use_vad and self.vad_comparator:
            print("ğŸ¯ æ‰§è¡ŒVADå¢å¼ºé¢„å¤„ç†...")
            vad_result = self.vad_comparator.align_speech_regions(standard_audio, user_audio)
            
            if vad_result and vad_result.get('success'):
                actual_standard_audio = vad_result['standard_speech_audio']
                actual_user_audio = vad_result['user_speech_audio']
                print(f"âœ“ VADå¤„ç†å®Œæˆï¼Œå¯¹é½è´¨é‡: {vad_result['alignment_quality']['quality_level']}")
                
                # 1.5 æ–‡æœ¬å¯¹é½ï¼ˆå¦‚æœå¯ç”¨ä¸”æä¾›äº†æœŸæœ›æ–‡æœ¬ï¼‰
                if enable_text_alignment and expected_text and hasattr(self.vad_comparator, 'vad_processor'):
                    print("ğŸ”¤ æ‰§è¡Œæ–‡æœ¬æ—¶åŸŸå¯¹é½...")
                    text_alignment_result = self.vad_comparator.vad_processor.align_text_with_vad(
                        expected_text, user_audio
                    )
                    # å°†æ–‡æœ¬å¯¹é½ç»“æœåˆå¹¶åˆ°VADç»“æœä¸­
                    vad_result.update(text_alignment_result)
                    asr_result = text_alignment_result.get('asr_result', {}) or {}
                    print(f"âœ“ æ–‡æœ¬å¯¹é½å®Œæˆï¼Œè¯†åˆ«æ–‡æœ¬: {asr_result.get('text', 'æ— ')}")
            else:
                print("âš ï¸ VADå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘")
        
        # 2. æå–éŸ³é«˜
        print("æå–æ ‡å‡†å‘éŸ³éŸ³é«˜...")
        standard_pitch = self.extractor.extract_pitch(actual_standard_audio)
        
        print("æå–ç”¨æˆ·å‘éŸ³éŸ³é«˜...")
        user_pitch = self.extractor.extract_pitch(actual_user_audio)
        
        # æ£€æŸ¥æå–ç»“æœ - æ”¾å®½æ‰‹æœºå½•éŸ³çš„éŸ³é«˜æ£€æµ‹è¦æ±‚
        if standard_pitch['valid_ratio'] < 0.05:
            return {'error': 'æ ‡å‡†å‘éŸ³éŸ³é«˜æå–å¤±è´¥ï¼Œå¯èƒ½æ˜¯éŸ³é¢‘è´¨é‡é—®é¢˜'}
        
        # ğŸ”§ æ‰‹æœºå½•éŸ³éŸ³é«˜æ£€æµ‹æ›´å®½æ¾çš„é˜ˆå€¼
        user_valid_ratio = user_pitch['valid_ratio']
        if user_valid_ratio < 0.01:  # è¿›ä¸€æ­¥é™ä½åˆ°0.01
            return {'error': f'ç”¨æˆ·å‘éŸ³éŸ³é«˜æå–å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½•éŸ³è´¨é‡ï¼ˆæœ‰æ•ˆéŸ³é«˜æ¯”ä¾‹ï¼š{user_valid_ratio:.1%}ï¼‰'}
        
        # å¦‚æœéŸ³é«˜æå–è´¨é‡è¾ƒä½ï¼Œç»™å‡ºå‹å¥½æç¤ºä½†ç»§ç»­å¤„ç†
        if user_valid_ratio < 0.05:
            print(f"âš ï¸ ç”¨æˆ·å½•éŸ³éŸ³é«˜è´¨é‡è¾ƒä½ï¼ˆ{user_valid_ratio:.1%}ï¼‰ï¼Œä½†ç»§ç»­å¤„ç†")
        
        # 3. å¯¹é½éŸ³é«˜æ›²çº¿ - ä½¿ç”¨å¢å¼ºå¯¹é½æˆ–æ ‡å‡†å¯¹é½
        if enhanced_alignment_result and enhanced_alignment_result['success']:
            print("âœ‚ï¸ æ‰§è¡Œå¢å¼ºéŸ³é«˜æ›²çº¿å¯¹é½...")
            
            # ä½¿ç”¨å¢å¼ºå¯¹é½ï¼šæˆªæ–­åˆ°TTSæ—¶é•¿å¹¶è¿›è¡ŒASRå¯¹é½
            tts_duration = enhanced_alignment_result['tts_effective_duration']
            alignment_strategy = enhanced_alignment_result['alignment']
            
            aligned_data = self.enhanced_aligner.truncate_pitch_curves_to_tts_duration(
                standard_pitch, user_pitch, tts_duration, alignment_strategy
            )
            
            if not aligned_data['success']:
                print("âš ï¸ å¢å¼ºå¯¹é½å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†å¯¹é½")
                aligned_data = self.aligner.align_pitch_curves(standard_pitch, user_pitch)
                # å¢å¼ºå¯¹é½å¤±è´¥ï¼Œæ¸…é™¤å¢å¼ºå¯¹é½ç»“æœæ ‡è®°
                enhanced_alignment_result = None
        else:
            print("å¯¹é½éŸ³é«˜æ›²çº¿ï¼ˆæ ‡å‡†æ–¹æ³•ï¼‰...")
            aligned_data = self.aligner.align_pitch_curves(standard_pitch, user_pitch)
        
        if len(aligned_data['aligned_standard']) == 0:
            return {'error': 'éŸ³é«˜æ›²çº¿å¯¹é½å¤±è´¥'}
        
        # 4. è®¡ç®—æ¯”è¾ƒæŒ‡æ ‡
        print("è®¡ç®—æ¯”è¾ƒæŒ‡æ ‡...")
        metrics = self._calculate_metrics(
            aligned_data['aligned_standard'],
            aligned_data['aligned_user']
        )
        
        # 5. ç»„åˆç»“æœ
        result = {
            'standard_pitch': standard_pitch,
            'user_pitch': user_pitch,
            'aligned_data': aligned_data,
            'metrics': metrics,
            'preprocessing_info': {
                'audio_normalized': True,
                'quality_enhanced': True,
                'pitch_baseline_aligned': True,
                'alignment_method': aligned_data.get('alignment_method', 'unknown'),
                'vad_enabled': self.use_vad,
                'vad_processing': vad_result is not None,
                'enhanced_alignment_enabled': self.use_enhanced_alignment,
                'enhanced_alignment_used': enhanced_alignment_result is not None
            },
            'vad_result': vad_result,
            'enhanced_alignment_result': enhanced_alignment_result,
            'processed_audio_paths': {
                'standard': actual_standard_audio,
                'user': actual_user_audio
            },
            'success': True
        }
        
        return result
    
    def _calculate_metrics(self, standard: np.ndarray, user: np.ndarray) -> dict:
        """è®¡ç®—æ¯”è¾ƒæŒ‡æ ‡"""
        
        # è¿‡æ»¤æœ‰æ•ˆå€¼
        valid_mask = ~(np.isnan(standard) | np.isnan(user))
        if np.sum(valid_mask) < 3:
            return {
                'correlation': 0.0,
                'rmse': float('inf'),
                'trend_consistency': 0.0,
                'pitch_range_ratio': 0.0,
                'valid_points': 0
            }
        
        std_valid = standard[valid_mask]
        user_valid = user[valid_mask]
        
        # 1. çš®å°”é€Šç›¸å…³ç³»æ•°
        try:
            correlation, _ = stats.pearsonr(std_valid, user_valid)
            if np.isnan(correlation):
                correlation = 0.0
        except:
            correlation = 0.0
        
        # 2. å‡æ–¹æ ¹è¯¯å·® (RMSE)
        try:
            rmse = np.sqrt(np.mean((std_valid - user_valid) ** 2))
            if np.isnan(rmse) or np.isinf(rmse):
                rmse = 1000.0  # è®¾ç½®ä¸€ä¸ªè¾ƒå¤§çš„é»˜è®¤å€¼è¡¨ç¤ºå·®å¼‚å¾ˆå¤§
        except:
            rmse = 1000.0
        
        # 3. è¶‹åŠ¿ä¸€è‡´æ€§ (è®¡ç®—å˜åŒ–æ–¹å‘çš„ä¸€è‡´æ€§)
        trend_consistency = self._calculate_trend_consistency(std_valid, user_valid)
        
        # 4. éŸ³é«˜èŒƒå›´æ¯”è¾ƒ
        std_range = np.max(std_valid) - np.min(std_valid)
        user_range = np.max(user_valid) - np.min(user_valid)
        
        if std_range > 0:
            pitch_range_ratio = min(user_range / std_range, std_range / user_range)
        else:
            pitch_range_ratio = 1.0 if user_range == 0 else 0.0
        
        # å®‰å…¨è½¬æ¢ï¼Œé¿å…NaNå’Œinf
        def safe_float(value):
            if np.isnan(value) or np.isinf(value):
                return 0.0
            return float(value)
        
        return {
            'correlation': safe_float(correlation),
            'rmse': safe_float(rmse),
            'trend_consistency': safe_float(trend_consistency),
            'pitch_range_ratio': safe_float(pitch_range_ratio),
            'valid_points': int(np.sum(valid_mask)),
            'std_mean': safe_float(np.mean(std_valid)),
            'user_mean': safe_float(np.mean(user_valid)),
            'std_std': safe_float(np.std(std_valid)),
            'user_std': safe_float(np.std(user_valid))
        }
    
    def _calculate_trend_consistency(self, standard: np.ndarray, user: np.ndarray) -> float:
        """
        è®¡ç®—éŸ³é«˜å˜åŒ–è¶‹åŠ¿çš„ä¸€è‡´æ€§ - é’ˆå¯¹å¬éšœäººå£«ä¼˜åŒ–
        åŒ…å«æ–¹å‘ä¸€è‡´æ€§ã€å¹…åº¦ç›¸ä¼¼æ€§å’Œå£°è°ƒæ¨¡å¼åŒ¹é…
        """
        if len(standard) < 3 or len(user) < 3:
            return 0.0
        
        try:
            # ğŸ¯ 1. è®¡ç®—å¤šé˜¶å·®åˆ†ï¼Œæ•æ‰ç»†å¾®å˜åŒ–
            std_diff1 = np.diff(standard)  # ä¸€é˜¶å·®åˆ†ï¼šå˜åŒ–é€Ÿåº¦
            user_diff1 = np.diff(user)
            
            std_diff2 = np.diff(std_diff1)  # äºŒé˜¶å·®åˆ†ï¼šå˜åŒ–åŠ é€Ÿåº¦
            user_diff2 = np.diff(user_diff1)
            
            # ğŸµ 2. æ–¹å‘ä¸€è‡´æ€§åˆ†æï¼ˆæƒé‡60%ï¼‰
            direction_consistency = self._calculate_direction_consistency(
                std_diff1, user_diff1
            )
            
            # ğŸ“Š 3. å¹…åº¦ç›¸ä¼¼æ€§åˆ†æï¼ˆæƒé‡25%ï¼‰
            magnitude_consistency = self._calculate_magnitude_consistency(
                std_diff1, user_diff1
            )
            
            # ğŸ¶ 4. å£°è°ƒæ¨¡å¼ä¸€è‡´æ€§ï¼ˆæƒé‡15%ï¼‰
            pattern_consistency = self._calculate_tone_pattern_consistency(
                std_diff1, user_diff1, std_diff2, user_diff2
            )
            
            # ğŸ¯ ç»¼åˆè¯„åˆ†
            total_consistency = (
                direction_consistency * 0.6 +
                magnitude_consistency * 0.25 +
                pattern_consistency * 0.15
            )
            
            return np.clip(total_consistency, 0.0, 1.0)
            
        except Exception as e:
            print(f"è¶‹åŠ¿ä¸€è‡´æ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def _calculate_direction_consistency(self, std_diff: np.ndarray, 
                                       user_diff: np.ndarray) -> float:
        """è®¡ç®—æ–¹å‘ä¸€è‡´æ€§ï¼Œè€ƒè™‘å˜åŒ–å¹…åº¦æƒé‡"""
        if len(std_diff) == 0:
            return 1.0
        
        # è®¡ç®—æ–¹å‘ç¬¦å·
        std_signs = np.sign(std_diff)
        user_signs = np.sign(user_diff)
        
        # å˜åŒ–å¹…åº¦ä½œä¸ºæƒé‡
        std_weights = np.abs(std_diff)
        std_weights = std_weights / np.sum(std_weights) if np.sum(std_weights) > 0 else np.ones_like(std_weights)
        
        # åŠ æƒæ–¹å‘ä¸€è‡´æ€§
        direction_matches = (std_signs == user_signs).astype(float)
        weighted_consistency = np.sum(direction_matches * std_weights)
        
        return weighted_consistency
    
    def _calculate_magnitude_consistency(self, std_diff: np.ndarray, 
                                       user_diff: np.ndarray) -> float:
        """è®¡ç®—å˜åŒ–å¹…åº¦çš„ç›¸ä¼¼æ€§"""
        if len(std_diff) == 0:
            return 1.0
        
        # å½’ä¸€åŒ–å˜åŒ–å¹…åº¦
        std_abs = np.abs(std_diff)
        user_abs = np.abs(user_diff)
        
        # é¿å…é™¤é›¶
        std_abs_norm = std_abs / (np.max(std_abs) + 1e-6)
        user_abs_norm = user_abs / (np.max(user_abs) + 1e-6)
        
        # è®¡ç®—å¹…åº¦ç›¸ä¼¼åº¦
        magnitude_diff = np.abs(std_abs_norm - user_abs_norm)
        magnitude_similarity = np.mean(1.0 - magnitude_diff)
        
        return np.clip(magnitude_similarity, 0.0, 1.0)
    
    def _calculate_tone_pattern_consistency(self, std_diff1: np.ndarray, 
                                          user_diff1: np.ndarray,
                                          std_diff2: np.ndarray, 
                                          user_diff2: np.ndarray) -> float:
        """è®¡ç®—å£°è°ƒæ¨¡å¼ä¸€è‡´æ€§ - æ£€æµ‹ä¸­æ–‡å£°è°ƒç‰¹å¾"""
        if len(std_diff2) == 0:
            return 1.0
        
        # ğŸµ æ£€æµ‹å£°è°ƒæ¨¡å¼
        std_pattern = self._identify_tone_pattern(std_diff1, std_diff2)
        user_pattern = self._identify_tone_pattern(user_diff1, user_diff2)
        
        # è®¡ç®—æ¨¡å¼åŒ¹é…åº¦
        pattern_match = self._compare_tone_patterns(std_pattern, user_pattern)
        
        return pattern_match
    
    def _identify_tone_pattern(self, diff1: np.ndarray, diff2: np.ndarray) -> str:
        """è¯†åˆ«éŸ³è°ƒå˜åŒ–æ¨¡å¼"""
        if len(diff1) < 2:
            return 'unknown'
        
        # åˆ†ææ•´ä½“è¶‹åŠ¿
        total_change = np.sum(diff1)
        monotonic_ratio = np.sum(np.abs(diff1)) / (np.abs(total_change) + 1e-6)
        
        # åˆ†æå˜åŒ–æ–¹å‘çš„å˜åŒ–ï¼ˆäºŒé˜¶å¯¼æ•°ï¼‰
        direction_changes = np.sum(np.abs(np.diff(np.sign(diff1))))
        
        # å£°è°ƒæ¨¡å¼åˆ¤æ–­
        if abs(total_change) < np.std(diff1) * 0.5:
            return 'flat'  # å¹³è°ƒï¼ˆé˜´å¹³ï¼‰
        elif total_change > 0 and monotonic_ratio > 0.7:
            return 'rising'  # å‡è°ƒï¼ˆé˜³å¹³ï¼‰
        elif total_change < 0 and monotonic_ratio > 0.7:
            return 'falling'  # é™è°ƒï¼ˆå»å£°ï¼‰
        elif direction_changes >= 2:
            return 'dipping'  # é™å‡è°ƒï¼ˆä¸Šå£°ï¼‰
        else:
            return 'complex'  # å¤æ‚å˜åŒ–
    
    def _compare_tone_patterns(self, pattern1: str, pattern2: str) -> float:
        """æ¯”è¾ƒä¸¤ä¸ªå£°è°ƒæ¨¡å¼çš„åŒ¹é…åº¦"""
        if pattern1 == pattern2:
            return 1.0
        
        # å£°è°ƒç›¸ä¼¼æ€§çŸ©é˜µ
        similarity_matrix = {
            ('flat', 'flat'): 1.0,
            ('rising', 'rising'): 1.0,
            ('falling', 'falling'): 1.0,
            ('dipping', 'dipping'): 1.0,
            ('flat', 'rising'): 0.3,
            ('flat', 'falling'): 0.3,
            ('rising', 'falling'): 0.2,
            ('dipping', 'complex'): 0.6,
            ('complex', 'complex'): 0.8,
        }
        
        # å¯¹ç§°æ€§
        key = (pattern1, pattern2)
        reverse_key = (pattern2, pattern1)
        
        if key in similarity_matrix:
            return similarity_matrix[key]
        elif reverse_key in similarity_matrix:
            return similarity_matrix[reverse_key]
        else:
            return 0.4  # é»˜è®¤ä¸­ç­‰ç›¸ä¼¼åº¦
    
    def calculate_vad_enhanced_score(self, comparison_result: dict) -> dict:
        """
        åŸºäºVADç»“æœè®¡ç®—å¢å¼ºè¯„åˆ†
        :param comparison_result: æ¯”è¾ƒç»“æœ
        :return: å¢å¼ºè¯„åˆ†ä¿¡æ¯
        """
        base_metrics = comparison_result.get('metrics', {})
        vad_result = comparison_result.get('vad_result')
        
        if not vad_result or not vad_result.get('success'):
            return {
                'enhanced_score': base_metrics.get('correlation', 0.0),
                'vad_bonus': 0.0,
                'alignment_quality_bonus': 0.0,
                'total_enhancement': 0.0
            }
        
        # åŸºç¡€ç›¸å…³æ€§åˆ†æ•°
        base_correlation = base_metrics.get('correlation', 0.0)
        
        # VADè´¨é‡åŠ æˆ
        alignment_quality = vad_result.get('alignment_quality', {})
        quality_score = alignment_quality.get('overall_score', 0.5)
        
        # è®¡ç®—VADåŠ æˆ (æœ€å¤šå¢åŠ 20%çš„åˆ†æ•°)
        vad_bonus = min(0.2, quality_score * 0.2)
        
        # è¯­éŸ³æ¯”ä¾‹ä¸€è‡´æ€§åŠ æˆ (æœ€å¤šå¢åŠ 10%çš„åˆ†æ•°)
        std_info = vad_result.get('standard_info', {})
        user_info = vad_result.get('user_info', {})
        
        std_ratio = std_info.get('speech_ratio', 0.5)
        user_ratio = user_info.get('speech_ratio', 0.5)
        ratio_diff = abs(std_ratio - user_ratio)
        
        ratio_bonus = max(0, (0.1 - ratio_diff)) if ratio_diff < 0.1 else 0
        
        # æ€»å¢å¼ºåˆ†æ•°
        total_enhancement = vad_bonus + ratio_bonus
        enhanced_score = min(1.0, base_correlation + total_enhancement)
        
        return {
            'enhanced_score': enhanced_score,
            'vad_bonus': vad_bonus,
            'alignment_quality_bonus': ratio_bonus,
            'total_enhancement': total_enhancement,
            'speech_ratio_consistency': 1.0 - ratio_diff if ratio_diff < 1.0 else 0.0
        }
    
    def compare_with_fun_asr_visualization(self, standard_audio: str, user_audio: str, 
                                         original_text: str, output_path: str) -> dict:
        """
        ä½¿ç”¨Fun-ASRè¿›è¡ŒTTSéŸ³é¢‘æ—¶é—´æˆ³åˆ†æå¹¶ç”Ÿæˆå¯è§†åŒ–ç»“æœ
        :param standard_audio: æ ‡å‡†å‘éŸ³éŸ³é¢‘è·¯å¾„ï¼ˆTTSç”Ÿæˆï¼‰
        :param user_audio: ç”¨æˆ·å‘éŸ³éŸ³é¢‘è·¯å¾„
        :param original_text: ç”ŸæˆTTSæ—¶ä½¿ç”¨çš„åŸå§‹æ–‡æœ¬
        :param output_path: å¯è§†åŒ–ç»“æœè¾“å‡ºè·¯å¾„
        :return: å®Œæ•´çš„æ¯”å¯¹ç»“æœ
        """
        try:
            print(f"ğŸ¯ å¼€å§‹Fun-ASRå¢å¼ºéŸ³é«˜æ¯”å¯¹åˆ†æ...")
            print(f"æ ‡å‡†éŸ³é¢‘: {standard_audio}")
            print(f"ç”¨æˆ·éŸ³é¢‘: {user_audio}")
            print(f"åŸå§‹æ–‡æœ¬: {original_text}")
            
            # 1. æ‰§è¡Œæ ‡å‡†éŸ³é«˜æ¯”å¯¹
            comparison_result = self.compare_pitch_curves(
                standard_audio, user_audio, original_text, True
            )
            
            if not comparison_result:
                print("âŒ åŸºç¡€éŸ³é«˜æ¯”å¯¹å¤±è´¥")
                return None
            
            # 2. è®¡ç®—è¯„åˆ†
            from scoring_algorithm import ScoringSystem
            scorer = ScoringSystem()
            score_result = scorer.calculate_score(comparison_result.get('metrics', {}), original_text)
            
            # 3. ç”ŸæˆFun-ASRå¢å¼ºå¯è§†åŒ–
            if self.use_fun_asr and FUN_ASR_AVAILABLE:
                try:
                    print("ğŸ“Š æ­£åœ¨ç”ŸæˆFun-ASRæ—¶é—´æˆ³å¯è§†åŒ–...")
                    visualizer = PitchVisualizationWithFunASR()
                    
                    success = visualizer.plot_comparison_with_fun_asr_timestamps(
                        comparison_result=comparison_result,
                        score_result=score_result,
                        output_path=output_path,
                        tts_audio_path=standard_audio,  # TTSéŸ³é¢‘ç”¨äºæ—¶é—´æˆ³åˆ†æ
                        original_text=original_text
                    )
                    
                    if success:
                        print(f"âœ… Fun-ASRå¢å¼ºå¯è§†åŒ–å®Œæˆ: {output_path}")
                    else:
                        print("âš ï¸ Fun-ASRå¯è§†åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ ‡å‡†å¯è§†åŒ–")
                        self._fallback_to_standard_visualization(
                            comparison_result, score_result, output_path, original_text
                        )
                        
                except Exception as e:
                    print(f"âš ï¸ Fun-ASRå¯è§†åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
                    self._fallback_to_standard_visualization(
                        comparison_result, score_result, output_path, original_text
                    )
            else:
                print("âš ï¸ Fun-ASRä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†å¯è§†åŒ–")
                self._fallback_to_standard_visualization(
                    comparison_result, score_result, output_path, original_text
                )
            
            # 4. æ„å»ºå®Œæ•´ç»“æœ
            result = {
                'comparison_result': comparison_result,
                'score_result': score_result,
                'visualization_path': output_path,
                'original_text': original_text,
                'fun_asr_enabled': self.use_fun_asr,
                'timestamp': comparison_result.get('timestamp')
            }
            
            print(f"ğŸ‰ Fun-ASRå¢å¼ºéŸ³é«˜æ¯”å¯¹åˆ†æå®Œæˆ!")
            return result
            
        except Exception as e:
            print(f"âŒ Fun-ASRå¢å¼ºéŸ³é«˜æ¯”å¯¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _fallback_to_standard_visualization(self, comparison_result, score_result, 
                                          output_path, original_text):
        """
        å›é€€åˆ°æ ‡å‡†å¯è§†åŒ–æ–¹æ³•
        """
        try:
            from visualization import PitchVisualization
            visualizer = PitchVisualization()
            
            text_alignment_data = comparison_result.get('text_alignment_data')
            
            success = visualizer.plot_pitch_comparison(
                comparison_result=comparison_result,
                score_result=score_result,
                output_path=output_path,
                input_text=original_text,
                text_alignment_data=text_alignment_data
            )
            
            if success:
                print(f"âœ… æ ‡å‡†å¯è§†åŒ–å®Œæˆ: {output_path}")
            else:
                print("âŒ æ ‡å‡†å¯è§†åŒ–ä¹Ÿå¤±è´¥äº†")
                
        except Exception as e:
            print(f"âŒ æ ‡å‡†å¯è§†åŒ–å›é€€å¤±è´¥: {e}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    from tts_module import TTSManager
    import os
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    Config.create_directories()
    
    # æµ‹è¯•æ¯”è¾ƒåŠŸèƒ½
    comparator = PitchComparator()
    
    # å¦‚æœæœ‰æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼Œå¯ä»¥è¿›è¡Œæ¯”è¾ƒ
    test_audio = "test_audio.wav"
    if os.path.exists(test_audio):
        # æå–éŸ³é«˜
        pitch_data = comparator.extractor.extract_pitch(test_audio)
        print(f"éŸ³é«˜æå–ç»“æœ:")
        print(f"  æ—¶é•¿: {pitch_data['duration']:.2f} ç§’")
        print(f"  æœ‰æ•ˆæ¯”ä¾‹: {pitch_data['valid_ratio']:.2%}")
        print(f"  å¹³å‡éŸ³é«˜: {np.nanmean(pitch_data['pitch_values']):.1f} Hz")
    else:
        print("æœªæ‰¾åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼Œè·³è¿‡æµ‹è¯•")
