# -*- coding: utf-8 -*-
"""
TTSæ¨¡å— - æ–‡æœ¬è½¬è¯­éŸ³åŠŸèƒ½
æ”¯æŒé˜¿é‡Œäº‘æƒ…æ„ŸTTSã€Edge TTSã€ç¦»çº¿TTS
ä¼˜å…ˆçº§ï¼šé˜¿é‡Œäº‘TTS > Edge TTS > ç¦»çº¿TTS
"""
import os
import logging
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Union
from config import Config

logger = logging.getLogger(__name__)

# å¯¼å…¥TTSå¼•æ“
try:
    from tts_engines.alibaba_emotion_tts import AlibabaEmotionTTS, create_alibaba_tts
    ALIBABA_TTS_AVAILABLE = True
except ImportError:
    ALIBABA_TTS_AVAILABLE = False
    print("âš ï¸ é˜¿é‡Œäº‘æƒ…æ„ŸTTSä¸å¯ç”¨ï¼Œè¯·å®‰è£…ç›¸å…³ä¾èµ–")

try:
    import edge_tts
    import asyncio
    EDGE_TTS_AVAILABLE = True
except ImportError:
    EDGE_TTS_AVAILABLE = False
    print("âš ï¸ Edge TTSä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install edge-tts")

class TTSBase(ABC):
    """TTSåŸºç±»"""
    
    @abstractmethod
    def synthesize(self, text: str, output_path: str, **kwargs) -> bool:
        """
        åˆæˆè¯­éŸ³
        :param text: è¦åˆæˆçš„æ–‡æœ¬
        :param output_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :param kwargs: å…¶ä»–å‚æ•°
        :return: æ˜¯å¦æˆåŠŸ
        """
        pass

class EdgeTTS(TTSBase):
    """Edge TTSå…è´¹æœåŠ¡"""
    
    def __init__(self):
        if not EDGE_TTS_AVAILABLE:
            raise ImportError("Edge TTS ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install edge-tts")
        
        self.voice = getattr(Config, 'EDGE_TTS_VOICE', 'zh-CN-XiaoxiaoNeural')
        self.rate = getattr(Config, 'EDGE_TTS_RATE', '+0%')
        self.volume = getattr(Config, 'EDGE_TTS_VOLUME', '+0%')
    
    def synthesize(self, text: str, output_path: str, **kwargs) -> bool:
        """ä½¿ç”¨Edge TTSåˆæˆè¯­éŸ³"""
        try:
            # è·å–å¯é€‰å‚æ•°
            voice = kwargs.get('voice', self.voice)
            rate = kwargs.get('rate', self.rate)
            volume = kwargs.get('volume', self.volume)
            
            # ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼ˆMP3æ ¼å¼ï¼‰
            temp_mp3_path = output_path.replace('.wav', '_temp.mp3')
            
            async def _synthesize():
                communicate = edge_tts.Communicate(text, voice, rate=rate, volume=volume)
                await communicate.save(temp_mp3_path)
            
            # è¿è¡Œå¼‚æ­¥å‡½æ•°
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(_synthesize())
            loop.close()
            
            # éªŒè¯ä¸´æ—¶æ–‡ä»¶
            if not os.path.exists(temp_mp3_path) or os.path.getsize(temp_mp3_path) == 0:
                logger.error("Edge TTSç”Ÿæˆä¸´æ—¶æ–‡ä»¶å¤±è´¥")
                return False
            
            # è½¬æ¢MP3åˆ°WAVæ ¼å¼
            try:
                import subprocess
                # ä½¿ç”¨ffmpegè½¬æ¢æ ¼å¼
                result = subprocess.run([
                    'ffmpeg', '-i', temp_mp3_path, 
                    '-acodec', 'pcm_s16le', '-ar', '22050', '-ac', '1',
                    '-y', output_path
                ], capture_output=True, text=True)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_mp3_path):
                    os.remove(temp_mp3_path)
                
                if result.returncode == 0:
                    if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                        logger.info(f"Edge TTSåˆæˆæˆåŠŸ: {output_path}")
                        return True
                    else:
                        logger.error("Edge TTSæ ¼å¼è½¬æ¢åæ–‡ä»¶ä¸ºç©º")
                        return False
                else:
                    logger.error(f"Edge TTSæ ¼å¼è½¬æ¢å¤±è´¥: {result.stderr}")
                    return False
                    
            except FileNotFoundError:
                # å¦‚æœæ²¡æœ‰ffmpegï¼Œå°è¯•ä½¿ç”¨pydub
                try:
                    from pydub import AudioSegment
                    audio = AudioSegment.from_mp3(temp_mp3_path)
                    audio.export(output_path, format="wav")
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_mp3_path):
                        os.remove(temp_mp3_path)
                    
                    if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                        logger.info(f"Edge TTSåˆæˆæˆåŠŸ: {output_path}")
                        return True
                    else:
                        logger.error("Edge TTSæ ¼å¼è½¬æ¢åæ–‡ä»¶ä¸ºç©º")
                        return False
                        
                except ImportError:
                    logger.error("Edge TTSæ ¼å¼è½¬æ¢å¤±è´¥ï¼šéœ€è¦ffmpegæˆ–pydub")
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_mp3_path):
                        os.remove(temp_mp3_path)
                    return False
                
        except Exception as e:
            logger.error(f"Edge TTSåˆæˆå¤±è´¥: {e}")
            return False

class OfflineTTS(TTSBase):
    """ç¦»çº¿TTSæœåŠ¡"""
    
    def __init__(self):
        try:
            import pyttsx3
            self.engine = pyttsx3.init()
            self.engine.setProperty('rate', 200)  # è¯­é€Ÿ
            self.engine.setProperty('volume', 0.8)  # éŸ³é‡
        except ImportError:
            raise ImportError("ç¦»çº¿TTSä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install pyttsx3")
    
    def synthesize(self, text: str, output_path: str, **kwargs) -> bool:
        """ä½¿ç”¨ç¦»çº¿TTSåˆæˆè¯­éŸ³"""
        try:
            # è®¾ç½®è¾“å‡ºæ–‡ä»¶
            self.engine.save_to_file(text, output_path)
            self.engine.runAndWait()
            
            # éªŒè¯æ–‡ä»¶
            if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                logger.info(f"ç¦»çº¿TTSåˆæˆæˆåŠŸ: {output_path}")
                return True
            else:
                logger.error("ç¦»çº¿TTSåˆæˆå¤±è´¥ï¼šæ–‡ä»¶æœªç”Ÿæˆæˆ–ä¸ºç©º")
                return False
                
        except Exception as e:
            logger.error(f"ç¦»çº¿TTSåˆæˆå¤±è´¥: {e}")
            return False

class TTSManager:
    """TTSç®¡ç†å™¨ï¼Œä¼˜å…ˆä½¿ç”¨é˜¿é‡Œäº‘æƒ…æ„ŸTTS"""
    
    def __init__(self):
        self.tts_engines = []
        self.emotion_engine = None  # ä¸“é—¨çš„æƒ…æ„ŸTTSå¼•æ“
        self.voice_profiles = {}
        self._init_engines()
        self._init_voice_profiles()
    
    def _init_engines(self):
        """åˆå§‹åŒ–å¯ç”¨çš„TTSå¼•æ“ - ä¼˜å…ˆçº§ï¼šé˜¿é‡Œäº‘ > Edge > ç¦»çº¿"""
        
        # 1. å°è¯•åˆå§‹åŒ–é˜¿é‡Œäº‘æƒ…æ„ŸTTS (æœ€é«˜ä¼˜å…ˆçº§)
        if ALIBABA_TTS_AVAILABLE and hasattr(Config, 'ALIBABA_TTS_CONFIG'):
            alibaba_config = getattr(Config, 'ALIBABA_TTS_CONFIG', {})
            if alibaba_config.get('enabled', False):
                try:
                    api_key = alibaba_config.get('api_key', '')
                    if api_key:
                        alibaba_tts = create_alibaba_tts(api_key)
                        if alibaba_tts:
                            self.emotion_engine = alibaba_tts
                            self.tts_engines.append(("é˜¿é‡Œäº‘æƒ…æ„ŸTTS", alibaba_tts))
                            print("âœ“ é˜¿é‡Œäº‘æƒ…æ„ŸTTS åˆå§‹åŒ–æˆåŠŸ")
                        else:
                            print("âœ— é˜¿é‡Œäº‘æƒ…æ„ŸTTS åˆå§‹åŒ–å¤±è´¥")
                    else:
                        print("âœ— é˜¿é‡Œäº‘TTS APIå¯†é’¥æœªé…ç½®")
                except Exception as e:
                    print(f"âœ— é˜¿é‡Œäº‘æƒ…æ„ŸTTS åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # 2. å°è¯•åˆå§‹åŒ–Edge TTS (å¤‡ç”¨)
        if EDGE_TTS_AVAILABLE:
            edge_config = getattr(Config, 'EDGE_TTS_CONFIG', {})
            if edge_config.get('enabled', True):
                try:
                    edge_tts = EdgeTTS()
                    self.tts_engines.append(("Edge TTS", edge_tts))
                    print("âœ“ Edge TTS åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    print(f"âœ— Edge TTS åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # 3. å°è¯•åˆå§‹åŒ–ç¦»çº¿TTS (æœ€åå¤‡ç”¨)
        try:
            offline_tts = OfflineTTS()
            self.tts_engines.append(("ç¦»çº¿TTS", offline_tts))
            print("âœ“ ç¦»çº¿TTS åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âœ— ç¦»çº¿TTS åˆå§‹åŒ–å¤±è´¥: {e}")
        
        if not self.tts_engines:
            raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„TTSå¼•æ“ï¼Œè¯·æ£€æŸ¥ä¾èµ–åŒ…å®‰è£…å’Œé…ç½®")
        
        print(f"å…±åˆå§‹åŒ–äº† {len(self.tts_engines)} ä¸ªTTSå¼•æ“")
    
    def _init_voice_profiles(self):
        """åˆå§‹åŒ–ä¸åŒè§’è‰²çš„è¯­éŸ³é…ç½®"""
        self.voice_profiles = {
            'standard': {
                'description': 'æ ‡å‡†å‘éŸ³',
                'emotion': 'neutral',
                'voice': 'zhimiao_emo'
            },
            'gentle': {
                'description': 'æ¸©æŸ”å¥³å£°',
                'emotion': 'gentle',
                'voice': 'zhimiao_emo'
            },
            'energetic': {
                'description': 'æ´»åŠ›å¥³å£°',
                'emotion': 'happy',
                'voice': 'zhimiao_emo'
            },
            'serious': {
                'description': 'ä¸¥è‚ƒç”·å£°',
                'emotion': 'serious',
                'voice': 'zhifeng_emo'
            }
        }
    
    def generate_standard_audio(self, text: str, output_path: str, voice_gender: str = 'female', voice_emotion: str = 'neutral', **kwargs) -> bool:
        """
        ç”Ÿæˆæ ‡å‡†å‘éŸ³éŸ³é¢‘
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            voice_gender: å£°éŸ³æ€§åˆ« ('female', 'male')
            voice_emotion: æƒ…æ„Ÿç±»å‹ ('neutral', 'happy', 'sad', etc.)
            **kwargs: å…¶ä»–å‚æ•°
                - quality: éŸ³è´¨è¦æ±‚ ('high', 'medium', 'low')
        
        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ¤ å¼€å§‹ç”Ÿæˆæ ‡å‡†å‘éŸ³éŸ³é¢‘: {text} (æ€§åˆ«: {voice_gender}, æƒ…æ„Ÿ: {voice_emotion})")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_path)
        if output_dir:  # åªæœ‰å½“æœ‰ç›®å½•éƒ¨åˆ†æ—¶æ‰åˆ›å»º
            os.makedirs(output_dir, exist_ok=True)
        
        # ä¼˜å…ˆä½¿ç”¨æƒ…æ„ŸTTS
        if self.emotion_engine:
            try:
                # æ ¹æ®æ€§åˆ«å’Œæƒ…æ„Ÿé€‰æ‹©å£°éŸ³
                emotion = voice_emotion or kwargs.get('emotion', 'neutral')
                
                if voice_gender == 'male':
                    if emotion == 'neutral':
                        voice = 'zhishuo'  # ç”·å£°æ ‡å‡†ï¼ˆçŸ¥ç¡•ï¼‰- ä»…æ”¯æŒä¸­æ€§
                        print(f"ğŸµ ä½¿ç”¨é˜¿é‡Œäº‘ç”·å£°TTS: voice={voice}, emotion={emotion}")
                    else:
                        # ç”·å£°ä¸æ”¯æŒæƒ…æ„Ÿï¼Œå›é€€åˆ°å¥³å£°æƒ…æ„Ÿæ¨¡å‹
                        voice = 'zhimiao_emo'
                        print(f"âš ï¸ ç”·å£°æš‚ä¸æ”¯æŒ {emotion} æƒ…æ„Ÿï¼Œä½¿ç”¨å¥³å£°æƒ…æ„Ÿæ¨¡å‹: voice={voice}, emotion={emotion}")
                else:
                    voice = 'zhimiao_emo'  # å¥³å£°ï¼ˆé»˜è®¤ï¼Œæ”¯æŒæƒ…æ„Ÿï¼‰
                    print(f"ğŸµ ä½¿ç”¨é˜¿é‡Œäº‘å¥³å£°æƒ…æ„ŸTTS: voice={voice}, emotion={emotion}")
                
                success = self.emotion_engine.synthesize(
                    text=text,
                    output_path=output_path,
                    emotion=emotion,
                    voice=voice,
                    **kwargs
                )
                
                if success and os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                    print(f"âœ“ ä½¿ç”¨é˜¿é‡Œäº‘æƒ…æ„ŸTTSæˆåŠŸç”ŸæˆéŸ³é¢‘")
                    return True
            except Exception as e:
                print(f"âœ— é˜¿é‡Œäº‘æƒ…æ„ŸTTSç”Ÿæˆå¤±è´¥: {e}")
        
        # å›é€€åˆ°å…¶ä»–TTSå¼•æ“
        for engine_name, engine in self.tts_engines:
            try:
                if engine == self.emotion_engine:
                    continue  # è·³è¿‡å·²ç»å°è¯•çš„æƒ…æ„Ÿå¼•æ“
                
                success = engine.synthesize(text, output_path, **kwargs)
                if success and os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                    print(f"âœ“ ä½¿ç”¨ {engine_name} æˆåŠŸç”ŸæˆéŸ³é¢‘")
                    return True
                    
            except Exception as e:
                print(f"âœ— {engine_name} ç”Ÿæˆå¤±è´¥: {e}")
                continue
        
        print("âœ— æ‰€æœ‰TTSå¼•æ“éƒ½æ— æ³•ç”ŸæˆéŸ³é¢‘")
        return False
    
    def generate_emotion_audio(self, text: str, emotion: str, output_path: str, **kwargs) -> bool:
        """
        ç”Ÿæˆå¸¦æƒ…æ„Ÿçš„éŸ³é¢‘
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            emotion: æƒ…æ„Ÿç±»å‹
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        if self.emotion_engine:
            return self.emotion_engine.synthesize(
                text=text,
                output_path=output_path,
                emotion=emotion,
                **kwargs
            )
        else:
            # å›é€€åˆ°æ ‡å‡†ç”Ÿæˆ
            print("âš ï¸ æƒ…æ„ŸTTSä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†TTS")
            return self.generate_standard_audio(text, output_path, **kwargs)
    
    def generate_dialogue_audio(self, text: str, output_path: str, 
                               role_type: str = 'standard', emotion: str = 'neutral', **kwargs) -> bool:
        """
        ç”Ÿæˆå¯¹è¯éŸ³é¢‘
        
        Args:
            text: å¯¹è¯æ–‡æœ¬
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            role_type: è§’è‰²ç±»å‹
            emotion: æƒ…æ„Ÿ
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ­ ç”Ÿæˆè§’è‰²å¯¹è¯éŸ³é¢‘: {role_type} ({emotion})")
        
        # è·å–è§’è‰²é…ç½®
        role_config = self.voice_profiles.get(role_type, self.voice_profiles['standard'])
        
        # åˆå¹¶é…ç½®
        synthesis_params = {
            'emotion': emotion,
            'voice': role_config.get('voice', 'zhimiao_emo'),
            **kwargs
        }
        
        return self.generate_standard_audio(text, output_path, **synthesis_params)
    
    def generate_ai_character_audio(self, text: str, output_path: str, 
                                   character_type: str = 'default', emotion: str = 'neutral', 
                                   scenario_context: str = '', **kwargs) -> bool:
        """
        ä¸“é—¨ä¸ºAIè§’è‰²ç”Ÿæˆå¸¦æƒ…æ„Ÿçš„å¯¹è¯éŸ³é¢‘
        
        Args:
            text: AIè§’è‰²å°è¯æ–‡æœ¬
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            character_type: AIè§’è‰²ç±»å‹ ('adult_male', 'adult_female', 'child', 'elder', etc.)
            emotion: æƒ…æ„Ÿç±»å‹ ('neutral', 'happy', 'sad', 'angry', 'gentle', 'serious')
            scenario_context: åœºæ™¯ä¸Šä¸‹æ–‡ä¿¡æ¯
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ­ ç”ŸæˆAIè§’è‰²éŸ³é¢‘: è§’è‰²={character_type}, æƒ…æ„Ÿ={emotion}, æ–‡æœ¬='{text[:50]}...'")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        # ä¼˜å…ˆä½¿ç”¨é˜¿é‡Œäº‘æƒ…æ„ŸTTS
        if self.emotion_engine:
            try:
                # æ ¹æ®è§’è‰²ç±»å‹æ˜ å°„åˆ°å…·ä½“çš„å‘éŸ³äºº
                voice_mapping = {
                    'adult_male': 'zhibing_emo',    # å¤šæƒ…æ„Ÿç”·å£°
                    'adult_female': 'zhimiao_emo',  # å¤šæƒ…æ„Ÿå¥³å£°
                    'young_male': 'zhibing_emo',    # å¹´è½»ç”·æ€§
                    'young_female': 'zhimiao_emo',  # å¹´è½»å¥³æ€§
                    'child': 'zhimiao_emo',         # å„¿ç«¥ï¼ˆç”¨å¥³å£°æ¨¡æ‹Ÿï¼‰
                    'elder_male': 'zhishuo',        # å¹´é•¿ç”·æ€§ï¼ˆæ ‡å‡†ç”·å£°ï¼‰
                    'elder_female': 'zhichu',       # å¹´é•¿å¥³æ€§ï¼ˆæ ‡å‡†å¥³å£°ï¼‰
                    'default': 'zhimiao_emo'        # é»˜è®¤å¤šæƒ…æ„Ÿå¥³å£°
                }
                
                voice = voice_mapping.get(character_type, 'zhimiao_emo')
                
                # æ ¹æ®åœºæ™¯ä¸Šä¸‹æ–‡è°ƒæ•´æƒ…æ„Ÿå¼ºåº¦
                adjusted_emotion = self._adjust_emotion_for_context(emotion, scenario_context)
                
                print(f"ğŸµ ä½¿ç”¨é˜¿é‡Œäº‘æƒ…æ„ŸTTS: voice={voice}, emotion={adjusted_emotion}")
                
                success = self.emotion_engine.synthesize(
                    text=text,
                    output_path=output_path,
                    voice=voice,
                    emotion=adjusted_emotion,
                    **kwargs
                )
                
                if success and os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                    print(f"âœ“ AIè§’è‰²éŸ³é¢‘ç”ŸæˆæˆåŠŸ: {output_path}")
                    return True
                else:
                    print(f"âœ— é˜¿é‡Œäº‘æƒ…æ„ŸTTSç”Ÿæˆå¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")
                    
            except Exception as e:
                print(f"âœ— é˜¿é‡Œäº‘æƒ…æ„ŸTTSç”ŸæˆAIè§’è‰²éŸ³é¢‘å¤±è´¥: {e}")
        
        # å›é€€åˆ°æ ‡å‡†TTS
        print("ğŸ”„ ä½¿ç”¨æ ‡å‡†TTSä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
        return self.generate_standard_audio(
            text=text,
            output_path=output_path,
            voice_gender='female' if 'female' in character_type else 'male',
            voice_emotion=emotion,
            **kwargs
        )
    
    def _adjust_emotion_for_context(self, emotion: str, context: str) -> str:
        """
        æ ¹æ®åœºæ™¯ä¸Šä¸‹æ–‡è°ƒæ•´æƒ…æ„Ÿè¡¨è¾¾
        
        Args:
            emotion: åŸå§‹æƒ…æ„Ÿ
            context: åœºæ™¯ä¸Šä¸‹æ–‡
        
        Returns:
            str: è°ƒæ•´åçš„æƒ…æ„Ÿ
        """
        # ç®€å•çš„ä¸Šä¸‹æ–‡æƒ…æ„Ÿè°ƒæ•´é€»è¾‘
        context_lower = context.lower()
        
        # å•†åŠ¡åœºæ™¯ - æ›´åŠ æ­£å¼
        if any(word in context_lower for word in ['å•†åŠ¡', 'å·¥ä½œ', 'ä¼šè®®', 'é¢è¯•', 'åŠå…¬']):
            if emotion == 'happy':
                return 'gentle'  # å•†åŠ¡åœºæ™¯çš„å¼€å¿ƒæ›´æ¸©å’Œ
            elif emotion in ['angry', 'sad']:
                return 'serious'  # å•†åŠ¡åœºæ™¯ä¸é€‚åˆå¼ºçƒˆæƒ…æ„Ÿ
        
        # å®¶åº­åœºæ™¯ - æ›´åŠ äº²åˆ‡
        elif any(word in context_lower for word in ['å®¶åº­', 'äº²å­', 'å®¶äºº', 'å­©å­']):
            if emotion == 'neutral':
                return 'gentle'  # å®¶åº­åœºæ™¯æ›´æ¸©æŸ”
        
        # å­¦ä¹ åœºæ™¯ - æ›´åŠ è€å¿ƒ
        elif any(word in context_lower for word in ['å­¦ä¹ ', 'æ•™å­¦', 'è¯¾å ‚', 'è€å¸ˆ', 'å­¦ç”Ÿ']):
            if emotion == 'neutral':
                return 'gentle'
            elif emotion == 'happy':
                return 'gentle'  # æ•™å­¦åœºæ™¯çš„å¼€å¿ƒåº”è¯¥æ˜¯é¼“åŠ±æ€§çš„
        
        return emotion  # é»˜è®¤è¿”å›åŸæƒ…æ„Ÿ
    
    def get_available_emotions(self) -> List[str]:
        """è·å–å¯ç”¨çš„æƒ…æ„Ÿç±»å‹"""
        if self.emotion_engine:
            return self.emotion_engine.get_available_emotions()
        else:
            return ['neutral']  # é»˜è®¤åªæœ‰ä¸­æ€§
    
    def get_available_voices(self) -> Dict[str, Dict]:
        """è·å–å¯ç”¨çš„å‘éŸ³äºº"""
        if self.emotion_engine:
            return self.emotion_engine.get_voice_info()
        else:
            return {}
    
    def get_available_voice_profiles(self) -> Dict[str, Dict]:
        """è·å–å¯ç”¨çš„è¯­éŸ³é…ç½®æ–‡ä»¶"""
        return self.voice_profiles.copy()
    
    def get_available_engines(self) -> List[str]:
        """è·å–å¯ç”¨çš„TTSå¼•æ“åˆ—è¡¨"""
        return [name for name, _ in self.tts_engines]
    
    def is_emotion_supported(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ”¯æŒæƒ…æ„ŸTTS"""
        return self.emotion_engine is not None

# å…¨å±€TTSç®¡ç†å™¨å®ä¾‹
_tts_manager = None

def get_tts_manager() -> TTSManager:
    """è·å–TTSç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _tts_manager
    if _tts_manager is None:
        _tts_manager = TTSManager()
    return _tts_manager

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # æµ‹è¯•TTSç®¡ç†å™¨
    tts_manager = get_tts_manager()
    
    # æµ‹è¯•æ ‡å‡†éŸ³é¢‘ç”Ÿæˆ
    success = tts_manager.generate_standard_audio(
        text="ä½ å¥½ï¼Œè¿™æ˜¯æµ‹è¯•éŸ³é¢‘ã€‚",
        output_path="test_output.mp3"
    )
    print(f"æ ‡å‡†éŸ³é¢‘ç”Ÿæˆ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
    
    # æµ‹è¯•æƒ…æ„ŸéŸ³é¢‘ç”Ÿæˆ
    if tts_manager.is_emotion_supported():
        success = tts_manager.generate_emotion_audio(
            text="æˆ‘ä»Šå¤©å¾ˆå¼€å¿ƒï¼",
            emotion="happy",
            output_path="test_emotion.mp3"
        )
        print(f"æƒ…æ„ŸéŸ³é¢‘ç”Ÿæˆ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
    
    # æ˜¾ç¤ºå¯ç”¨åŠŸèƒ½
    print(f"å¯ç”¨å¼•æ“: {tts_manager.get_available_engines()}")
    print(f"å¯ç”¨æƒ…æ„Ÿ: {tts_manager.get_available_emotions()}")