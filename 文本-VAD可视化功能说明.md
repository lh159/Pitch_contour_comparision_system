# 文本-VAD可视化功能说明

## 功能概述

本系统新增了**文本与语音活动区域（VAD）对应的可视化功能**，能够直观地展示TTS生成的标准发音和用户说话的汉字文本在时域上的对应关系，让用户清楚地看到发音的时间差异和文本匹配情况。

## 🎯 核心功能

### 1. 语音活动检测（VAD）
- **技术实现**：集成阿里达摩院FunASR本地VAD模型
- **功能**：自动检测音频中的语音活动段，过滤静音部分
- **优势**：提高音高比对的精确度，专注于有效语音区域

### 2. 自动语音识别（ASR）
- **技术实现**：使用FunASR本地ASR模型
- **功能**：识别用户语音内容并提供词级时间戳
- **输出**：每个词汇的开始和结束时间

### 3. 智能文本对齐
- **算法**：基于编辑距离的文本对齐算法
- **功能**：将期望文本（TTS原文）与识别文本进行智能匹配
- **处理**：支持插入、删除、替换等对齐操作

### 4. 时域可视化展示
- **双层显示**：
  - 上层：音高曲线对比图（含VAD区域标注）
  - 下层：文本时域对齐图
- **颜色编码**：根据匹配质量使用不同颜色
- **详细信息**：显示时间戳、匹配度、统计信息

## 📊 可视化效果

### 主要音高对比图
```
🎵 音高曲线对比 - 实时差异分析
┌─────────────────────────────────────┐
│  ╭─ 🎯 标准发音 (TTS)                │
│ ╱│  ╲                               │
│╱ │   ╲     🎤 您的发音              │
│  │段1 ╲   ╱                        │
│  │     ╲ ╱  段2                     │
│  │      ╳                          │
│  │     ╱ ╲                         │
│  └────────────────────────────────  │
└─────────────────────────────────────┘
     0s    1s    2s    3s    4s
```

### 文本时域对齐图
```
📝 文本时域对齐分析 - 语音段与文字对应关系
段2 ┌───────────────┐ 85% │标准: 世界  │
    │ 0.8s    1.5s  │     │识别: 世界  │
段1 ┌─────────┐ 92%       │标准: 你好  │
    │0.1s  0.7s│           │识别: 你好  │
    └─────────────────────────────────┘
         时间 (秒)
```

## 🔧 使用方法

### 1. 基础使用
```python
from main_controller import PitchComparisonSystem

# 初始化系统
system = PitchComparisonSystem()
system.initialize()

# 处理带文本对齐的音频
result = system.process_word(
    text="你好世界",
    user_audio_path="user_recording.wav"
)

# 查看文本对齐结果
if result.get('success'):
    vad_result = result['comparison'].get('vad_result')
    if vad_result:
        print("识别文本:", vad_result.get('asr_result', {}).get('text'))
        print("文本对齐:", vad_result.get('text_alignment'))
```

### 2. 高级配置
```python
# 自定义VAD参数
from vad_module import VADProcessor

vad = VADProcessor()

# 执行文本对齐
alignment_result = vad.align_text_with_vad(
    expected_text="你好世界",
    audio_path="user_audio.wav"
)
```

## 📈 实现原理

### 1. 文本对齐算法流程
```
输入: 期望文本 + 用户音频
  ↓
VAD检测 → 语音段: [(0.1s, 0.7s), (0.8s, 1.5s)]
  ↓
ASR识别 → 文本+时间戳: [("你好", 0.1s, 0.7s), ("世界", 0.8s, 1.5s)]
  ↓
文本对齐 → 匹配结果: [
  {expected: "你好", recognized: "你好", match: "exact"},
  {expected: "世界", recognized: "世界", match: "exact"}
]
  ↓
VAD映射 → 段落关联: [
  {segment: 1, text: "你好", quality: 92%},
  {segment: 2, text: "世界", quality: 85%}
]
```

### 2. 匹配质量计算
- **完全匹配**：1.0分（绿色显示）
- **部分匹配**：0.5分（橙色显示）
- **无匹配**：0.0分（红色显示）
- **总体质量**：加权平均分

## 🎨 可视化详解

### 颜色编码系统
| 匹配质量 | 颜色 | 含义 |
|---------|------|------|
| ≥80% | 🟢 绿色 | 匹配良好 |
| 50-79% | 🟡 橙色 | 匹配一般 |
| <50% | 🔴 红色 | 匹配较差 |

### 显示元素说明
1. **VAD区域背景**：浅绿色背景标识语音活动区域
2. **段落编号**：段1、段2...标识不同的语音段
3. **文本标注**：
   - 上方蓝色：期望文本（标准）
   - 下方绿色/红色：识别文本（实际）
4. **时间戳**：精确显示每个词的时间范围
5. **匹配度指示**：百分比显示匹配质量

## 🚀 技术优势

### 1. 直观的时域对比
- **实时反馈**：用户可以看到自己的发音在哪个时间点
- **精确定位**：定位到具体的字词发音问题
- **视觉对比**：标准发音vs实际发音的直观比较

### 2. 智能错误检测
- **漏字检测**：显示用户遗漏的词汇
- **多字检测**：标识用户额外说出的内容
- **发音错误**：识别发音不准确的词汇

### 3. 学习辅助功能
- **针对性练习**：根据文本对齐结果进行针对性改进
- **进度跟踪**：记录每次练习的文本匹配情况
- **个性化建议**：基于文本对齐质量提供改进建议

## 📋 配置要求

### 必需依赖
```bash
# 安装FunASR（语音处理）
pip install funasr>=1.0.0

# 安装DashScope（可选，用于在线API）
pip install dashscope>=1.0.0

# 安装jieba（中文分词）
pip install jieba>=0.42.1
```

### 系统要求
- **Python**: 3.8+
- **内存**: 建议8GB+（用于加载ASR模型）
- **存储**: 模型文件需要约2GB空间
- **网络**: 首次下载模型需要网络连接

## 🔧 配置说明

### config.py 配置项
```python
# VAD相关配置
VAD_ENERGY_THRESHOLD = 0.02        # 能量阈值
VAD_MIN_SPEECH_DURATION = 0.1      # 最小语音时长
VAD_MAX_SILENCE_DURATION = 0.3     # 最大静音时长

# ASR模型配置
ALIBABA_VAD_MODEL = "damo/speech_fsmn_vad_zh-cn-16k-common-pytorch"
ALIBABA_ASR_MODEL = "damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
```

## 🎯 使用场景

### 1. 语言学习
- **发音练习**：学习者可以看到自己的发音时间和标准发音的差异
- **节奏训练**：理解语音的时间节奏和停顿
- **准确性评估**：客观评价发音的准确性

### 2. 语音训练
- **播音主持**：训练语音的清晰度和节奏感
- **语言治疗**：辅助语言障碍康复训练
- **外语教学**：帮助教师和学生分析发音问题

### 3. 研究应用
- **语音学研究**：分析语音时域特征
- **语言对比**：研究不同语言的时域差异
- **模型评估**：评估TTS和ASR系统的性能

## 🔍 故障排除

### 常见问题

1. **VAD检测不准确**
   ```
   解决方案：
   - 检查音频质量，确保信噪比足够
   - 调整VAD_ENERGY_THRESHOLD参数
   - 使用更好的录音设备
   ```

2. **ASR识别错误**
   ```
   解决方案：
   - 确保发音清晰，语速适中
   - 检查音频格式（推荐16kHz，16bit WAV）
   - 避免背景噪声干扰
   ```

3. **文本对齐偏差**
   ```
   解决方案：
   - 检查期望文本是否与实际发音一致
   - 确保音频时长不要过长（建议<30秒）
   - 检查中文分词是否正确
   ```

## 📊 性能优化建议

### 1. 音频质量优化
- **采样率**：16kHz（符合模型要求）
- **位深度**：16bit
- **格式**：WAV（无压缩）
- **时长**：建议5-30秒

### 2. 系统性能优化
- **模型缓存**：首次加载后模型会缓存在内存中
- **批处理**：支持批量处理多个音频文件
- **并行处理**：VAD和音高提取可以并行执行

### 3. 可视化优化
- **图片大小**：可调整DPI以适应不同显示需求
- **字体设置**：自动检测系统中文字体
- **颜色主题**：支持自定义配色方案

## 🔄 更新记录

### v1.0.0 (当前版本)
- ✅ 集成FunASR VAD和ASR功能
- ✅ 实现智能文本对齐算法
- ✅ 添加文本时域可视化图表
- ✅ 支持中文分词和处理
- ✅ 完整的错误处理和降级机制

### 计划功能
- 🔄 支持英语等其他语言
- 🔄 优化文本对齐算法精度
- 🔄 添加语音情感分析
- 🔄 实现实时语音处理
- 🔄 支持多说话人场景

---

## 💡 最佳实践

1. **录音建议**：
   - 使用质量较好的麦克风
   - 在安静环境中录音
   - 保持适中的语速和音量

2. **文本准备**：
   - 确保期望文本与实际要说的内容一致
   - 避免过长的句子（建议<20字）
   - 使用标准的中文表达

3. **结果解读**：
   - 关注匹配质量低的段落
   - 分析时间差异较大的词汇
   - 结合音高曲线理解发音问题

通过这个功能，用户可以更直观地理解自己的发音特点，进行有针对性的改进，显著提升语音学习效果！
