# -*- coding: utf-8 -*-
"""
ä¸­æ–‡å£°è°ƒåˆ†ææ¨¡å—
ä¸“é—¨é’ˆå¯¹å¬éšœäººå£«çš„éŸ³è°ƒè®­ç»ƒéœ€æ±‚ï¼Œæä¾›ç²¾ç¡®çš„å£°è°ƒè¯†åˆ«å’Œæ¯”å¯¹åŠŸèƒ½
"""
import numpy as np
import re
from typing import Dict, List, Tuple, Optional
from config import Config

class ChineseToneAnalyzer:
    """ä¸­æ–‡å£°è°ƒåˆ†æå™¨ - ä¸“ä¸ºå¬éšœäººå£«éŸ³è°ƒè®­ç»ƒä¼˜åŒ–"""
    
    def __init__(self):
        self.tone_config = Config.CHINESE_TONE_CONFIG
        self.tone_patterns = self.tone_config['tone_patterns']
        self.tone_weights = self.tone_config['tone_weights']
        
        # å£°è°ƒæ£€æµ‹é˜ˆå€¼
        self.thresholds = {
            'flat_tolerance': 0.15,      # å¹³è°ƒå®¹å·®
            'rising_slope': 0.3,         # å‡è°ƒæœ€å°æ–œç‡
            'falling_slope': -0.3,       # é™è°ƒæœ€å¤§æ–œç‡
            'dipping_complexity': 0.4,   # ä¸Šå£°å¤æ‚åº¦é˜ˆå€¼
            'min_duration': 0.1          # æœ€å°åˆ†ææ—¶é•¿(ç§’)
        }
    
    def analyze_pitch_based_tones(self, pitch_values: np.ndarray, 
                                 times: np.ndarray, 
                                 text: str) -> List[int]:
        """
        åŸºäºéŸ³é«˜æ›²çº¿åˆ†ææ–‡æœ¬çš„å£°è°ƒåºåˆ—
        :param pitch_values: éŸ³é«˜åºåˆ—
        :param times: æ—¶é—´åºåˆ—
        :param text: ä¸­æ–‡æ–‡æœ¬ï¼ˆç”¨äºç¡®å®šåˆ†æ®µæ•°é‡ï¼‰
        :return: å£°è°ƒåºåˆ— [1,2,3,4,0] å¯¹åº” [é˜´å¹³,é˜³å¹³,ä¸Šå£°,å»å£°,è½»å£°]
        """
        if len(pitch_values) < 5 or len(text.strip()) == 0:
            return [1] * len(text.strip())  # é»˜è®¤è¿”å›é˜´å¹³
        
        # è¿‡æ»¤æœ‰æ•ˆéŸ³é«˜
        valid_mask = ~np.isnan(pitch_values)
        if np.sum(valid_mask) < 3:
            return [1] * len(text.strip())
        
        valid_pitch = pitch_values[valid_mask]
        valid_times = times[valid_mask]
        
        # éŸ³é«˜å½’ä¸€åŒ–ï¼ˆç›¸å¯¹éŸ³é«˜ï¼‰
        normalized_pitch = self._normalize_pitch_for_tone_analysis(valid_pitch)
        
        # æŒ‰å­—ç¬¦æ•°åˆ†æ®µåˆ†æ
        char_count = len(text.strip())
        segments = self._segment_pitch_by_characters(
            normalized_pitch, valid_times, char_count
        )
        
        detected_tones = []
        for segment in segments:
            if len(segment['pitch']) > 2:
                tone_info = self._detect_tone_from_segment(segment)
                detected_tones.append(tone_info['tone_type'])
            else:
                detected_tones.append(0)  # é»˜è®¤è½»å£°
        
        return detected_tones
    
    def analyze_pitch_tones(self, pitch_values: np.ndarray, 
                           times: np.ndarray, 
                           expected_tones: List[int] = None) -> Dict:
        """
        åˆ†æéŸ³é«˜æ›²çº¿çš„å£°è°ƒç‰¹å¾
        :param pitch_values: éŸ³é«˜åºåˆ—
        :param times: æ—¶é—´åºåˆ—
        :param expected_tones: æœŸæœ›çš„å£°è°ƒåºåˆ—
        :return: å£°è°ƒåˆ†æç»“æœ
        """
        if len(pitch_values) < 5:
            return {'error': 'éŸ³é¢‘å¤ªçŸ­ï¼Œæ— æ³•åˆ†æå£°è°ƒ'}
        
        # è¿‡æ»¤æœ‰æ•ˆéŸ³é«˜
        valid_mask = ~np.isnan(pitch_values)
        if np.sum(valid_mask) < 3:
            return {'error': 'æœ‰æ•ˆéŸ³é«˜ç‚¹å¤ªå°‘'}
        
        valid_pitch = pitch_values[valid_mask]
        valid_times = times[valid_mask]
        
        # éŸ³é«˜å½’ä¸€åŒ–ï¼ˆç›¸å¯¹éŸ³é«˜ï¼‰
        normalized_pitch = self._normalize_pitch_for_tone_analysis(valid_pitch)
        
        # åˆ†æ®µåˆ†æï¼ˆå‡è®¾æ¯ä¸ªå­—å ç­‰æ—¶é•¿ï¼‰
        if expected_tones:
            segments = self._segment_pitch_by_characters(
                normalized_pitch, valid_times, len(expected_tones)
            )
            tone_analysis = []
            
            for i, segment in enumerate(segments):
                if len(segment['pitch']) > 2:
                    detected_tone = self._detect_tone_from_segment(segment)
                    expected_tone = expected_tones[i] if i < len(expected_tones) else 1
                    
                    tone_analysis.append({
                        'segment_index': i,
                        'detected_tone': detected_tone,
                        'expected_tone': expected_tone,
                        'confidence': detected_tone.get('confidence', 0.5),
                        'match': self._compare_tones(
                            detected_tone['tone_type'], expected_tone
                        )
                    })
        else:
            # æ•´ä½“åˆ†æ
            detected_tone = self._detect_tone_from_segment({
                'pitch': normalized_pitch,
                'times': valid_times
            })
            tone_analysis = [detected_tone]
        
        return {
            'tone_analysis': tone_analysis,
            'overall_tone_accuracy': self._calculate_overall_accuracy(tone_analysis),
            'pitch_statistics': self._calculate_pitch_statistics(valid_pitch)
        }
    
    def _normalize_pitch_for_tone_analysis(self, pitch_values: np.ndarray) -> np.ndarray:
        """ä¸ºå£°è°ƒåˆ†æä¼˜åŒ–çš„éŸ³é«˜å½’ä¸€åŒ–"""
        # ä½¿ç”¨å¯¹æ•°å˜æ¢ï¼Œæ›´ç¬¦åˆéŸ³é«˜æ„ŸçŸ¥
        log_pitch = np.log2(pitch_values / np.min(pitch_values))
        
        # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
        normalized = (log_pitch - np.min(log_pitch)) / (np.max(log_pitch) - np.min(log_pitch))
        
        return normalized
    
    def _segment_pitch_by_characters(self, pitch: np.ndarray, 
                                   times: np.ndarray, 
                                   num_chars: int) -> List[Dict]:
        """æŒ‰å­—ç¬¦æ•°åˆ†æ®µéŸ³é«˜åºåˆ—"""
        segments = []
        total_duration = times[-1] - times[0]
        char_duration = total_duration / num_chars
        
        for i in range(num_chars):
            start_time = times[0] + i * char_duration
            end_time = start_time + char_duration
            
            # æ‰¾åˆ°æ—¶é—´æ®µå†…çš„éŸ³é«˜ç‚¹
            mask = (times >= start_time) & (times < end_time)
            if np.sum(mask) > 0:
                segments.append({
                    'pitch': pitch[mask],
                    'times': times[mask],
                    'start_time': start_time,
                    'end_time': end_time,
                    'character_index': i
                })
        
        return segments
    
    def _detect_tone_from_segment(self, segment: Dict) -> Dict:
        """ä»éŸ³é«˜ç‰‡æ®µæ£€æµ‹å£°è°ƒ"""
        pitch = segment['pitch']
        times = segment['times']
        
        if len(pitch) < 2:
            return {'tone_type': 1, 'confidence': 0.0, 'pattern': 'unknown'}
        
        # è®¡ç®—éŸ³é«˜å˜åŒ–ç‰¹å¾
        features = self._extract_tone_features(pitch, times)
        
        # å£°è°ƒåˆ†ç±»
        tone_type, confidence = self._classify_tone(features, pitch, times)
        
        return {
            'tone_type': tone_type,
            'confidence': confidence,
            'pattern': self.tone_patterns.get(tone_type, 'unknown'),
            'features': features
        }
    
    def _extract_tone_features(self, pitch: np.ndarray, times: np.ndarray) -> Dict:
        """æå–å£°è°ƒç‰¹å¾"""
        # åŸºæœ¬ç»Ÿè®¡ç‰¹å¾
        mean_pitch = np.mean(pitch)
        std_pitch = np.std(pitch)
        pitch_range = np.max(pitch) - np.min(pitch)
        
        # è¶‹åŠ¿ç‰¹å¾
        total_change = pitch[-1] - pitch[0]
        linear_slope = total_change / (times[-1] - times[0]) if len(times) > 1 else 0
        
        # å•è°ƒæ€§ç‰¹å¾
        diff = np.diff(pitch)
        monotonic_ratio = np.sum(diff > 0) / len(diff) if len(diff) > 0 else 0.5
        
        # å˜åŒ–å¤æ‚åº¦
        direction_changes = np.sum(np.abs(np.diff(np.sign(diff))))
        complexity = direction_changes / len(diff) if len(diff) > 0 else 0
        
        # å³°å€¼ç‰¹å¾
        peak_position = np.argmax(pitch) / len(pitch)
        valley_position = np.argmin(pitch) / len(pitch)
        
        return {
            'mean_pitch': mean_pitch,
            'std_pitch': std_pitch,
            'pitch_range': pitch_range,
            'total_change': total_change,
            'linear_slope': linear_slope,
            'monotonic_ratio': monotonic_ratio,
            'complexity': complexity,
            'peak_position': peak_position,
            'valley_position': valley_position,
            'duration': times[-1] - times[0] if len(times) > 1 else 0
        }
    
    def _classify_tone(self, features: Dict, pitch: np.ndarray = None, times: np.ndarray = None) -> Tuple[int, float]:
        """åŸºäºç‰¹å¾åˆ†ç±»å£°è°ƒ - æ”¹è¿›çš„ç®—æ³•"""
        slope = features['linear_slope']
        complexity = features['complexity']
        monotonic_ratio = features['monotonic_ratio']
        total_change = features['total_change']
        peak_pos = features['peak_position']
        valley_pos = features['valley_position']
        pitch_range = features['pitch_range']
        
        print(f"ğŸ” å£°è°ƒåˆ†ç±»ç‰¹å¾: slope={slope:.3f}, complexity={complexity:.3f}, "
              f"monotonic_ratio={monotonic_ratio:.3f}, total_change={total_change:.3f}")
        
        # å£°è°ƒåˆ†ç±»é€»è¾‘ - åŸºäºä¸­æ–‡å£°è°ƒçš„å®é™…ç‰¹å¾
        
        # 1. é˜´å¹³ï¼ˆç¬¬ä¸€å£°ï¼‰- é«˜å¹³è°ƒï¼ŒéŸ³é«˜ç›¸å¯¹å¹³ç¨³
        if (abs(total_change) < 0.2 and complexity < 0.3 and 
            abs(slope) < 0.15):
            return 1, 0.85
        
        # 2. é˜³å¹³ï¼ˆç¬¬äºŒå£°ï¼‰- å‡è°ƒï¼Œä»ä¸­ä½éŸ³å‡åˆ°é«˜éŸ³
        elif (slope > 0.2 and monotonic_ratio > 0.6 and 
              total_change > 0.15 and complexity < 0.4):
            return 2, 0.9
        
        # 3. ä¸Šå£°ï¼ˆç¬¬ä¸‰å£°ï¼‰- é™å‡è°ƒï¼Œå…ˆé™åå‡ï¼Œæœ€å¤æ‚
        # åˆ†æå‰åŠéƒ¨åˆ†å’ŒååŠéƒ¨åˆ†çš„è¶‹åŠ¿
        mid_point = len(times) // 2
        if mid_point > 2:
            first_half = pitch[:mid_point] if len(pitch) > mid_point else pitch
            second_half = pitch[mid_point:] if len(pitch) > mid_point else pitch
            
            first_trend = np.polyfit(range(len(first_half)), first_half, 1)[0] if len(first_half) > 1 else 0
            second_trend = np.polyfit(range(len(second_half)), second_half, 1)[0] if len(second_half) > 1 else 0
            
            # ä¸Šå£°ç‰¹å¾ï¼šå‰åŠä¸‹é™ï¼ŒååŠä¸Šå‡ï¼Œæœ‰æ˜æ˜¾è°·ç‚¹
            is_dipping = (first_trend < -0.05 and second_trend > 0.05 and 
                         0.2 < valley_pos < 0.8 and pitch_range > 0.15)
            
            print(f"ğŸ” ä¸Šå£°æ£€æµ‹: first_trend={first_trend:.3f}, second_trend={second_trend:.3f}, "
                  f"valley_pos={valley_pos:.3f}, is_dipping={is_dipping}")
            
            if is_dipping:
                return 3, 0.9
        
        # å¤‡é€‰ä¸Šå£°æ£€æµ‹ï¼šåŸºäºå¤æ‚åº¦å’Œå˜åŒ–èŒƒå›´
        high_complexity = complexity > 0.4
        mid_valley = 0.2 < valley_pos < 0.8
        moderate_range = pitch_range > 0.25
        
        if (high_complexity and mid_valley and moderate_range):
            return 3, 0.75
        
        # 4. å»å£°ï¼ˆç¬¬å››å£°ï¼‰- é™è°ƒï¼Œä»é«˜éŸ³å¿«é€Ÿä¸‹é™
        elif (slope < -0.2 and monotonic_ratio < 0.4 and 
              total_change < -0.15 and complexity < 0.4):
            return 4, 0.9
        
        # å¤‡é€‰åˆ¤æ–­é€»è¾‘
        else:
            # åŸºäºä¸»è¦ç‰¹å¾çš„æ¬¡è¦åˆ¤æ–­
            if total_change > 0.1 and slope > 0:
                return 2, 0.6  # å€¾å‘é˜³å¹³ï¼ˆå‡è°ƒï¼‰
            elif total_change < -0.1 and slope < 0:
                return 4, 0.6  # å€¾å‘å»å£°ï¼ˆé™è°ƒï¼‰
            elif complexity > 0.3:
                return 3, 0.5  # å€¾å‘ä¸Šå£°ï¼ˆå¤æ‚å˜åŒ–ï¼‰
            else:
                return 1, 0.5  # é»˜è®¤é˜´å¹³ï¼ˆå¹³è°ƒï¼‰
    
    def _compare_tones(self, detected: int, expected: int) -> Dict:
        """æ¯”è¾ƒæ£€æµ‹å£°è°ƒä¸æœŸæœ›å£°è°ƒ"""
        if detected == expected:
            return {'match': True, 'accuracy': 1.0, 'type': 'perfect'}
        
        # å£°è°ƒç›¸ä¼¼åº¦çŸ©é˜µ
        similarity_scores = {
            (1, 2): 0.3, (1, 3): 0.2, (1, 4): 0.2,
            (2, 3): 0.4, (2, 4): 0.1,
            (3, 4): 0.3
        }
        
        key = (min(detected, expected), max(detected, expected))
        similarity = similarity_scores.get(key, 0.0)
        
        return {
            'match': False,
            'accuracy': similarity,
            'type': 'partial' if similarity > 0.2 else 'mismatch'
        }
    
    def _calculate_overall_accuracy(self, tone_analysis: List[Dict]) -> float:
        """è®¡ç®—æ•´ä½“å£°è°ƒå‡†ç¡®åº¦"""
        if not tone_analysis:
            return 0.0
        
        total_accuracy = 0.0
        total_weight = 0.0
        
        for analysis in tone_analysis:
            if 'match' in analysis:
                accuracy = analysis['match']['accuracy']
                confidence = analysis.get('confidence', 0.5)
                expected_tone = analysis.get('expected_tone', 1)
                
                # å£°è°ƒé‡è¦æ€§æƒé‡
                tone_weight = self.tone_weights.get(expected_tone, 1.0)
                
                weighted_accuracy = accuracy * confidence * tone_weight
                total_accuracy += weighted_accuracy
                total_weight += tone_weight
        
        return total_accuracy / total_weight if total_weight > 0 else 0.0
    
    def _calculate_pitch_statistics(self, pitch_values: np.ndarray) -> Dict:
        """è®¡ç®—éŸ³é«˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'mean': float(np.mean(pitch_values)),
            'std': float(np.std(pitch_values)),
            'min': float(np.min(pitch_values)),
            'max': float(np.max(pitch_values)),
            'range': float(np.max(pitch_values) - np.min(pitch_values)),
            'median': float(np.median(pitch_values))
        }
    
    def get_tone_feedback(self, tone_analysis: List[Dict], 
                         target_language: str = 'chinese') -> str:
        """
        ä¸ºå¬éšœäººå£«ç”Ÿæˆä¸“é—¨çš„å£°è°ƒåé¦ˆå»ºè®®
        """
        if not tone_analysis:
            return "æ— æ³•åˆ†æå£°è°ƒï¼Œè¯·æ£€æŸ¥å½•éŸ³è´¨é‡ã€‚"
        
        feedback_parts = []
        
        for i, analysis in enumerate(tone_analysis):
            char_num = i + 1
            detected = analysis.get('detected_tone', {}).get('tone_type', 1)
            expected = analysis.get('expected_tone', 1)
            confidence = analysis.get('confidence', 0.5)
            
            if analysis.get('match', {}).get('match', False):
                feedback_parts.append(f"ç¬¬{char_num}ä¸ªå­—çš„å£°è°ƒå¾ˆå‡†ç¡®ï¼")
            else:
                tone_names = {1: 'é˜´å¹³(ä¸€å£°)', 2: 'é˜³å¹³(äºŒå£°)', 3: 'ä¸Šå£°(ä¸‰å£°)', 4: 'å»å£°(å››å£°)'}
                expected_name = tone_names.get(expected, 'æœªçŸ¥')
                detected_name = tone_names.get(detected, 'æœªçŸ¥')
                
                feedback_parts.append(
                    f"ç¬¬{char_num}ä¸ªå­—åº”è¯¥æ˜¯{expected_name}ï¼Œ"
                    f"æ‚¨å‘çš„æ˜¯{detected_name}ã€‚"
                )
                
                # æä¾›å…·ä½“æ”¹è¿›å»ºè®®
                if expected == 1:  # é˜´å¹³
                    feedback_parts.append("  ğŸ’¡ å»ºè®®ï¼šä¿æŒéŸ³é«˜å¹³ç¨³ï¼Œä¸è¦æœ‰æ˜æ˜¾å‡é™ã€‚")
                elif expected == 2:  # é˜³å¹³
                    feedback_parts.append("  ğŸ’¡ å»ºè®®ï¼šéŸ³è°ƒä»ä½å¾€é«˜ä¸Šå‡ï¼Œåƒç–‘é—®å¥ã€‚")
                elif expected == 3:  # ä¸Šå£°
                    feedback_parts.append("  ğŸ’¡ å»ºè®®ï¼šå…ˆè½»å¾®ä¸‹é™ï¼Œç„¶åæ˜æ˜¾ä¸Šå‡ã€‚")
                elif expected == 4:  # å»å£°
                    feedback_parts.append("  ğŸ’¡ å»ºè®®ï¼šéŸ³è°ƒä»é«˜å¾€ä½ä¸‹é™ï¼Œè¦æœ‰åŠ›ã€‚")
        
        overall_accuracy = self._calculate_overall_accuracy(tone_analysis)
        
        if overall_accuracy > 0.8:
            feedback_parts.append("\nğŸŒŸ æ€»ä½“è¡¨ç°ä¼˜ç§€ï¼æ‚¨çš„å£°è°ƒæŒæ¡å¾—å¾ˆå¥½ã€‚")
        elif overall_accuracy > 0.6:
            feedback_parts.append("\nğŸ‘ æ€»ä½“è¡¨ç°è‰¯å¥½ï¼Œç»§ç»­ç»ƒä¹ ä¼šæ›´å¥½ã€‚")
        else:
            feedback_parts.append("\nğŸ’ª å£°è°ƒè¿˜éœ€è¦å¤šç»ƒä¹ ï¼Œé‡ç‚¹å…³æ³¨éŸ³è°ƒçš„å‡é™å˜åŒ–ã€‚")
        
        return "\n".join(feedback_parts)

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
if __name__ == '__main__':
    analyzer = ChineseToneAnalyzer()
    
    # æµ‹è¯•æ–‡æœ¬å£°è°ƒåˆ†æ
    test_text = "ä½ å¥½"
    tones = analyzer.analyze_text_tones(test_text)
    print(f"æ–‡æœ¬ '{test_text}' çš„å£°è°ƒåºåˆ—: {tones}")
    
    # æµ‹è¯•éŸ³é«˜å£°è°ƒåˆ†æ
    # æ¨¡æ‹ŸéŸ³é«˜æ•°æ®
    test_pitch = np.array([200, 210, 220, 215, 210, 205, 200])
    test_times = np.linspace(0, 1, len(test_pitch))
    
    result = analyzer.analyze_pitch_tones(test_pitch, test_times, [3, 3])
    print(f"éŸ³é«˜å£°è°ƒåˆ†æç»“æœ: {result}")
